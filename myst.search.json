{"version":"1","records":[{"hierarchy":{"lvl1":"Welcome to the Astro Research Preparation Series!"},"type":"lvl1","url":"/intro","position":0},{"hierarchy":{"lvl1":"Welcome to the Astro Research Preparation Series!"},"content":"","type":"content","url":"/intro","position":1},{"hierarchy":{"lvl1":"Welcome to the Astro Research Preparation Series!","lvl2":"Lecture 1: UNIX, Filesystems, Environments, and the Python Ecosystem"},"type":"lvl2","url":"/intro#lecture-1-unix-filesystems-environments-and-the-python-ecosystem","position":2},{"hierarchy":{"lvl1":"Welcome to the Astro Research Preparation Series!","lvl2":"Lecture 1: UNIX, Filesystems, Environments, and the Python Ecosystem"},"content":"\n\n","type":"content","url":"/intro#lecture-1-unix-filesystems-environments-and-the-python-ecosystem","position":3},{"hierarchy":{"lvl1":"Welcome to the Astro Research Preparation Series!","lvl3":"Preface: Some things to keep in mind over the next nine weeks","lvl2":"Lecture 1: UNIX, Filesystems, Environments, and the Python Ecosystem"},"type":"lvl3","url":"/intro#preface-some-things-to-keep-in-mind-over-the-next-nine-weeks","position":4},{"hierarchy":{"lvl1":"Welcome to the Astro Research Preparation Series!","lvl3":"Preface: Some things to keep in mind over the next nine weeks","lvl2":"Lecture 1: UNIX, Filesystems, Environments, and the Python Ecosystem"},"content":"\n\nCoding is tough!\n\nLearning how to code is like learning a new language. It takes a long time to become comfortable, and the more you practice coding the easier it gets!\n\nWe are a community\n\nWe want this to be a space where we all feel comfortable speaking up, asking questions, and sharing ideas. All of the instructors learned from each other while preparing for this series (because, as per point 1, coding is tough), and we want that same spirit of community learning to be upheld in this space!\n\nWe are learning data science\n\nComputer science is a broader discipline that encompasses the study of algorithms, software engineering, operating systems, and more, while data science is focused on extracting insights from data (observational or simulated) using a combination of computer science, statistics, and domain-specific knowledge.\n\nToday, we are not doing Python! We will start with Python next week!\n\n","type":"content","url":"/intro#preface-some-things-to-keep-in-mind-over-the-next-nine-weeks","position":5},{"hierarchy":{"lvl1":"Welcome to the Astro Research Preparation Series!","lvl3":"Lesson Agenda","lvl2":"Lecture 1: UNIX, Filesystems, Environments, and the Python Ecosystem"},"type":"lvl3","url":"/intro#lesson-agenda","position":6},{"hierarchy":{"lvl1":"Welcome to the Astro Research Preparation Series!","lvl3":"Lesson Agenda","lvl2":"Lecture 1: UNIX, Filesystems, Environments, and the Python Ecosystem"},"content":"Intro + Preface: Done!\n\nFilesystems, UNIX, and Terminal\n\nQuestion Break\n\nInstalling Python + Virtual Environments","type":"content","url":"/intro#lesson-agenda","position":7},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data"},"type":"lvl1","url":"/unix","position":0},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data"},"content":"","type":"content","url":"/unix","position":1},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"What is a Filesystem?"},"type":"lvl3","url":"/unix#what-is-a-filesystem","position":2},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"What is a Filesystem?"},"content":"A filesystem is a way of organizing and storing data on a computer. It provides a structure for how data is stored and accessed. In the context of your computer, think of it as a file cabinet where you organize and store your files. Each file is stored in a specific location known as a directory or folder.\n\n","type":"content","url":"/unix#what-is-a-filesystem","position":3},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Directories and Folders","lvl3":"What is a Filesystem?"},"type":"lvl4","url":"/unix#directories-and-folders","position":4},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Directories and Folders","lvl3":"What is a Filesystem?"},"content":"On macOS, you might be familiar with the Finder application, which allows you to navigate through directories and see the contents of your computer’s filesystem in a graphical way. Directories, also known as folders, are containers that hold files or other directories.\n\nIn the example above, “Documents” is a directory that can contain multiple files. Understanding the concept of directories is crucial for organizing and managing your data, especially in research.\n\nFinder is not enough\n\nIn research, you eventually find that simply using user friendly interfaces like Finder to navigate through your filesystems will not be enough. There are many reasons we might need something more that will be explained throughout this tutorial! To give one example, sometimes applications will need to be installed from command line rather than having an easy installer for you to use.\n\n","type":"content","url":"/unix#directories-and-folders","position":5},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"Enter: UNIX and Terminal"},"type":"lvl3","url":"/unix#enter-unix-and-terminal","position":6},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"Enter: UNIX and Terminal"},"content":"UNIX is a powerful and versatile operating system that has been widely used in scientific computing, including astronomy and data science. It provides a command-line interface (CLI; also called the shell or the terminal) for interacting with the computer’s operating system. While modern versions of UNIX, such as Linux, macOS, and others, have evolved, they still retain the core principles and commands that originated with the original UNIX system.\n\nThe terminal is a text-based interface that allows users to interact with their computer’s operating system by typing commands. Unlike graphical user interfaces (GUIs) like Finder, which use visual elements like windows and buttons, the terminal relies on text commands.\n\nA note on terminology:\n\nOperating Systems: UNIX, Linux, macOS, Windows, Debian\n\nCLIs: Command line, terminal, shell (specific CLI)\n\nShell Languages: bash, zsh\n\n","type":"content","url":"/unix#enter-unix-and-terminal","position":7},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"Key Components of the Terminal:"},"type":"lvl3","url":"/unix#key-components-of-the-terminal","position":8},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"Key Components of the Terminal:"},"content":"Prompt: The prompt displays information about the system’s current state and awaits your command.\n\nCommand Line: This is where you input commands. You type a command and press Enter to execute it.\n\nOutput: After executing a command, the terminal provides output, displaying information or responses from the system.\n\nIn practice, your default mac terminal might look something like this:\n\n\n\nNote\n\nYou can also customize your terminal display to look nicer! I’m happy to help provide some tips and tricks on customizing your terminal at a later time, but you should also try it out for yourself!\n\n","type":"content","url":"/unix#key-components-of-the-terminal","position":9},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"Anatomy of a UNIX Command:"},"type":"lvl3","url":"/unix#anatomy-of-a-unix-command","position":10},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"Anatomy of a UNIX Command:"},"content":"Understanding the anatomy of a UNIX command is crucial for effectively using the command line. Let’s break down the key components: command, options/flags, and arguments.\n\nA UNIX command typically follows the structure:command [options/flags] [arguments]\n\nCommand:\n\nThe primary action you want the computer to perform.\n\nExamples: ls, cd, cp, mv, echo, etc.\n\nOptions/Flags:\n\nFlags modify the behavior of the command.\n\nUsually preceded by a hyphen (-) or double hyphen (--).\n\nExamples: -l, -a, --verbose, --force, etc.\n\nArguments:\n\nThe entities upon which the command acts.\n\nCan be file names, directories, strings, etc.\n\nExamples: file.txt, directory/, string, etc.\n\n","type":"content","url":"/unix#anatomy-of-a-unix-command","position":11},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Example Commands:","lvl3":"Anatomy of a UNIX Command:"},"type":"lvl4","url":"/unix#example-commands","position":12},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Example Commands:","lvl3":"Anatomy of a UNIX Command:"},"content":"Basic Command:ls\n\nCommand: ls\n\nOptions/Flags: None\n\nArguments: None\n\nCommand with Options:ls -l\n\nCommand: ls\n\nOptions/Flags: -l\n\nArguments: None\n\nCommand with Arguments:cp file.txt backup/\n\nCommand: cp\n\nOptions/Flags: None\n\nArguments: file.txt, backup/\n\n","type":"content","url":"/unix#example-commands","position":13},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"Common UNIX Commands"},"type":"lvl3","url":"/unix#common-unix-commands","position":14},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"Common UNIX Commands"},"content":"","type":"content","url":"/unix#common-unix-commands","position":15},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"1. pwd - Print Working Directory","lvl3":"Common UNIX Commands"},"type":"lvl4","url":"/unix#id-1-pwd-print-working-directory","position":16},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"1. pwd - Print Working Directory","lvl3":"Common UNIX Commands"},"content":"The pwd command is used to print the current working directory, which is the directory you are currently in within the file system.pwd\n\nThis command will display the full path to the current directory.\n\n","type":"content","url":"/unix#id-1-pwd-print-working-directory","position":17},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"2. ls - List Files","lvl3":"Common UNIX Commands"},"type":"lvl4","url":"/unix#id-2-ls-list-files","position":18},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"2. ls - List Files","lvl3":"Common UNIX Commands"},"content":"The ls command is used to list the files and directories in the current directory.ls\n\nThis command provides a simple listing of the files and directories in the current location.\n\n","type":"content","url":"/unix#id-2-ls-list-files","position":19},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"3. cd - Change Directory","lvl3":"Common UNIX Commands"},"type":"lvl4","url":"/unix#id-3-cd-change-directory","position":20},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"3. cd - Change Directory","lvl3":"Common UNIX Commands"},"content":"The cd command is used to change the current working directory. You can move to a different directory by specifying the path.cd /path/to/directory\n\nUse cd .. to move up one level in the directory hierarchy.\n\nExercise One: Using Terminal\n\nIn your shell/terminal (Terminal on Mac, Ubuntu on WSL), try\n\ncd .\n\ncd ..\n\ncd ...\n\nWhat do you think each of these do (without looking it up)? Now try\n\nls -l\n\nls -a\n\nWhat do you think these are doing?\n\nUnderstanding and practicing these basic commands will give you the foundation to navigate and interact with the file system using the UNIX command line. As we progress in the workshop, we’ll explore more advanced commands and concepts.\n\n","type":"content","url":"/unix#id-3-cd-change-directory","position":21},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl2":"Why are we doing this?"},"type":"lvl2","url":"/unix#why-are-we-doing-this","position":22},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl2":"Why are we doing this?"},"content":"Open Question\n\nNow, that you have seen a bit of what UNIX + terminal can do, can you think of any reasons why understanding how to use these tools is useful for astronomy research?\n\n","type":"content","url":"/unix#why-are-we-doing-this","position":23},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"1. Organizing Data","lvl2":"Why are we doing this?"},"type":"lvl4","url":"/unix#id-1-organizing-data","position":24},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"1. Organizing Data","lvl2":"Why are we doing this?"},"content":"When you conduct research, you often work with large datasets and various files. Knowing how to navigate through directories using the command line is essential. Let’s say you have to migrate a bunch of data files into a different location on your computer. You can use the following commands:\n# Create a subdirectory to organize the files\nmkdir data_files\n\n# Move all files with a specific extension (e.g., .txt) into the subdirectory\nmv *.txt data_files/\n\n\nThe mkdir data_files command creates a new subdirectory named “data_files” in the current directory. Then the mv *.txt data_files/ command moves all files with the extension “.txt” into the “data_files” subdirectory. There are lots of different ways you can change these commands to move your data in different ways:\n\nyou can customize the file extension based on your specific data files\n\nyou can specify arbitrary folders to move files between rather than using the current directory\n\nyou could use keywords in the filenames to select files rather than their extensions\n\nUNIX commands are incredibly flexible and can become incredibly complicated. There will almost always be a solution your specific problem!\n\n","type":"content","url":"/unix#id-1-organizing-data","position":25},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"2. Navigating to Data in your Code","lvl2":"Why are we doing this?"},"type":"lvl4","url":"/unix#id-2-navigating-to-data-in-your-code","position":26},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"2. Navigating to Data in your Code","lvl2":"Why are we doing this?"},"content":"Understanding filesystems becomes crucial when writing code. Your code will not know where your data lives unless you tell it. If your code throws an error like “File not found” or “No such file or directory,” it’s often because the file is not in the specified directory (or there’s a typo in the file name).\n\nYou will see examples of specifying the path to the data once we start working with Python in the coming weeks!\n\n","type":"content","url":"/unix#id-2-navigating-to-data-in-your-code","position":27},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"3. Executing Code, Managing Dependencies, Version Control, and More!","lvl2":"Why are we doing this?"},"type":"lvl4","url":"/unix#id-3-executing-code-managing-dependencies-version-control-and-more","position":28},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"3. Executing Code, Managing Dependencies, Version Control, and More!","lvl2":"Why are we doing this?"},"content":"Understanding UNIX + Filesystems is important for many many more aspects of research beyond data management! We can’t get into all of these now, but as a preview:\n\nWhen we want to ``execute\" python code, we can do it from command line\n\nWhen we want to remotely operate another computer (for instance, at a telescope or a supercomputer cluster)\n\nWhen we want to manage code installations + packages\n\n","type":"content","url":"/unix#id-3-executing-code-managing-dependencies-version-control-and-more","position":29},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl2":"Text Editors: Vim and Nano"},"type":"lvl2","url":"/unix#text-editors-vim-and-nano","position":30},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl2":"Text Editors: Vim and Nano"},"content":"\n\n","type":"content","url":"/unix#text-editors-vim-and-nano","position":31},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"Vim","lvl2":"Text Editors: Vim and Nano"},"type":"lvl3","url":"/unix#vim","position":32},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"Vim","lvl2":"Text Editors: Vim and Nano"},"content":"Vim (Vi Improved) is a powerful and highly configurable text editor that is widely used in the programming community. It operates in different modes, allowing users to navigate, edit, and manipulate text efficiently. Vim has a steeper learning curve, but its super versatile and its my favorite.","type":"content","url":"/unix#vim","position":33},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Basic Vim Commands","lvl3":"Vim","lvl2":"Text Editors: Vim and Nano"},"type":"lvl4","url":"/unix#basic-vim-commands","position":34},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Basic Vim Commands","lvl3":"Vim","lvl2":"Text Editors: Vim and Nano"},"content":"Normal Mode: Used for navigating and manipulating text. You start in normal mode, and can press Esc to return to normal mode.\n\nh, j, k, l, or arrow keys: Move left, down, up, and right, respectively.\n\ndd: Delete a line.\n\nyy: Copy a line.\n\np: Paste the copied or deleted text.\n\nInsert Mode: Used for inserting or editing text. Press i to enter Insert Mode.\n\nYou can type to insert your desired text.\n\nVisual Mode Used for selecting text. Press v to enter Visual Mode.\n\nYou can select blocks of text (to copy/cut/paste different amounts of text)\n\nSpecial sub-modes: visual line mode (V) or visual block mode (<C-V>)\n\nCommand Mode: Used for executing commands. : to enter command mode.\n\n:w: Save changes.\n\n:q: Quit Vim (without changes) or :q! to force quit and delete unsaved changes\n\n:wq or :x or ZZ: Save and quit.\n\nYou can also do cool things like find and replace in this mode!\n\n","type":"content","url":"/unix#basic-vim-commands","position":35},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"Nano","lvl2":"Text Editors: Vim and Nano"},"type":"lvl3","url":"/unix#nano","position":36},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl3":"Nano","lvl2":"Text Editors: Vim and Nano"},"content":"Nano is a straightforward and user-friendly text editor that is beginner-friendly. It provides a simple interface for editing text files and is particularly suitable for quick edits or when a full-featured editor like Vim might be overwhelming.","type":"content","url":"/unix#nano","position":37},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Basic Nano Commands","lvl3":"Nano","lvl2":"Text Editors: Vim and Nano"},"type":"lvl4","url":"/unix#basic-nano-commands","position":38},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Basic Nano Commands","lvl3":"Nano","lvl2":"Text Editors: Vim and Nano"},"content":"Saving Changes:\n\nPress Ctrl + O to write changes.\n\nPress Enter to confirm the file name.\n\nExiting Nano:\n\nPress Ctrl + X to exit Nano.\n\nEditing Text:\n\nUse arrow keys to navigate.\n\nUse Backspace to delete characters.\n\nPress Ctrl + K to cut a line.\n\nPress Ctrl + U to paste the cut line.\n\n","type":"content","url":"/unix#basic-nano-commands","position":39},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Choosing an Editor","lvl3":"Nano","lvl2":"Text Editors: Vim and Nano"},"type":"lvl4","url":"/unix#choosing-an-editor","position":40},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Choosing an Editor","lvl3":"Nano","lvl2":"Text Editors: Vim and Nano"},"content":"The choice between Vim and Nano often depends on personal preference and familiarity. Vim’s power lies in its extensive features, while Nano excels in simplicity and ease of use. Both editors offer efficient ways to manipulate and edit text, and the choice ultimately depends on your comfort level and requirements.\n\n","type":"content","url":"/unix#choosing-an-editor","position":41},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl2":"Piping UNIX Commands"},"type":"lvl2","url":"/unix#piping-unix-commands","position":42},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl2":"Piping UNIX Commands"},"content":"Piping involves directing the output of one command as input to another command. The symbol for piping is |. This allows you to chain commands together, creating powerful and flexible workflows.\n\n","type":"content","url":"/unix#piping-unix-commands","position":43},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Example 1: Basic Pipe between Two Commands","lvl2":"Piping UNIX Commands"},"type":"lvl4","url":"/unix#example-1-basic-pipe-between-two-commands","position":44},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Example 1: Basic Pipe between Two Commands","lvl2":"Piping UNIX Commands"},"content":"ls -l | grep \"txt\"\n\nThe ls -l command lists files in long format.\n\nThe output of ls -l is piped (|) to the grep \"txt\" command.\n\ngrep \"txt\" searches for lines containing the string “txt” in the output.\n\nOpen Question\n\nIs there any unexpected behavior with this command? How could it get you to the wrong answer?\n\n","type":"content","url":"/unix#example-1-basic-pipe-between-two-commands","position":45},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Example 2: Saving Output using Piping","lvl2":"Piping UNIX Commands"},"type":"lvl4","url":"/unix#example-2-saving-output-using-piping","position":46},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl4":"Example 2: Saving Output using Piping","lvl2":"Piping UNIX Commands"},"content":"You can also pipe the output of a UNIX command into a text file to save it. Here’s an example:# List all files in the current directory and save the output to a text file\nls -l > file_list.txt\n\nAgain, the ls -l command lists files in long format.\n\nThe > symbol redirects the output of the command to a file.\n\nfile_list.txt is the name of the text file where the output will be saved.\n\nAfter executing this command, the detailed listing of files in the current directory will be saved in the file_list.txt file.\n\nExercise Two: Experimenting with Commands\n\nIn your shell/terminal (Terminal on Mac, Ubuntu on WSL), try\n\nls | wc\n\nls -l | wc\n\nls | wc -l\n\nWhat do you think each of these do?\n\n","type":"content","url":"/unix#example-2-saving-output-using-piping","position":47},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl2":"And that’s it!"},"type":"lvl2","url":"/unix#and-thats-it","position":48},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl2":"And that’s it!"},"content":"\n\n","type":"content","url":"/unix#and-thats-it","position":49},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl2":"Appendix: Useful UNIX commands for your reference"},"type":"lvl2","url":"/unix#appendix-useful-unix-commands-for-your-reference","position":50},{"hierarchy":{"lvl1":"Introduction to UNIX and Filesystems: Navigating and Managing Data","lvl2":"Appendix: Useful UNIX commands for your reference"},"content":"Here’s a list of some important UNIX commands that can serve as a quick reference:\n\npwd: Print the current working directory.\n\nls: List files and directories in the current directory.\n\ncd: Change the current working directory.\n\ncd /path/to/directory: Change to the specified directory.\n\ncd ..: Move up one level in the directory hierarchy.\n\nmkdir: Create a new directory.\n\nmkdir new_directory: Create a directory named “new_directory”.\n\ncp: Copy files or directories.\n\ncp file.txt /path/to/destination: Copy “file.txt” to the specified destination.\n\nmv: Move or rename files or directories.\n\nmv old_name new_name: Rename a file or directory.\n\nmv file.txt /path/to/destination: Move “file.txt” to the specified destination.\n\nrm: Remove files or directories.\n\nrm file.txt: Remove “file.txt”.\n\nrm -r directory: Remove a directory and its contents.\n\ncat: Display the content of a file.\n\ncat file.txt: Display the content of “file.txt”.\n\necho: Print text to the terminal.\n\necho \"Hello, World!\": Print the text “Hello, World!”.\n\nman: Display the manual or help for a command.\n\nman ls: Show the manual for the ls command.\n\nchmod: Change file permissions.\n\nchmod +x script.sh: Add execute permission to a script.\n\ngrep: Search for a pattern in files.\n\ngrep pattern file.txt: Search for “pattern” in “file.txt”.\n\nps: Display information about running processes.\n\nps aux: Show detailed information about all processes.\n\nkill: Terminate a process.\n\nkill process_id: Terminate the process with the specified ID.\n\nnano or vim: Text editors for creating and editing files.\n\nnano filename.txt: Open “filename.txt” in the Nano text editor.\n\nThese commands cover basic file and directory manipulation, text file viewing, process management, and more.","type":"content","url":"/unix#appendix-useful-unix-commands-for-your-reference","position":51},{"hierarchy":{"lvl1":"The Python Ecosystem and Virtual Environments"},"type":"lvl1","url":"/environments","position":0},{"hierarchy":{"lvl1":"The Python Ecosystem and Virtual Environments"},"content":"Now that we have a foundational understanding of UNIX and filesystems, let’s explore the Python programming language and its ecosystem. Python is widely used in scientific computing, and understanding its installation, package management, and the use of virtual environments is crucial.\n\n","type":"content","url":"/environments","position":1},{"hierarchy":{"lvl1":"The Python Ecosystem and Virtual Environments","lvl2":"Python Installation and Package Management"},"type":"lvl2","url":"/environments#python-installation-and-package-management","position":2},{"hierarchy":{"lvl1":"The Python Ecosystem and Virtual Environments","lvl2":"Python Installation and Package Management"},"content":"Python can be installed in different ways on your computer. Usually, when we use python we also use external libraries. An external library is basically a collection of useful code written by someone else that you can acess without having to rewrite it yourself (you will learn more about these over the next few weeks). Python relies on package managers to install, update, and manage external libraries. The two primary package managers are:\n\npip: The default Python package installer.\n\nExample: pip install package_name\n\nConda: A cross-language package manager that simplifies dependency management.\n\nExample: conda install package_name\n\nUnderstanding how to use these package managers is essential for incorporating external libraries into your Python projects. You might also encounter homebrew or MacPorts. These are two other popular package managers, but they are not as common in astronomy.\n\n","type":"content","url":"/environments#python-installation-and-package-management","position":3},{"hierarchy":{"lvl1":"The Python Ecosystem and Virtual Environments","lvl3":"Using Conda as a Package Manager","lvl2":"Python Installation and Package Management"},"type":"lvl3","url":"/environments#using-conda-as-a-package-manager","position":4},{"hierarchy":{"lvl1":"The Python Ecosystem and Virtual Environments","lvl3":"Using Conda as a Package Manager","lvl2":"Python Installation and Package Management"},"content":"When we use conda, we have the option of using different distributions:\n\nMiniconda: A minimal installer for the Conda package manager, which only includes Conda and Python.\n\nAnaconda: A distribution that includes Python, Conda, and a large array of pre installed packages.\n\nOne of the features of conda (as opposed to pip) is that we can create virtual environments. You should all now have miniconda installed, so we can start making a virtual environment!\n\n","type":"content","url":"/environments#using-conda-as-a-package-manager","position":5},{"hierarchy":{"lvl1":"The Python Ecosystem and Virtual Environments","lvl2":"Python Virtual Environments"},"type":"lvl2","url":"/environments#python-virtual-environments","position":6},{"hierarchy":{"lvl1":"The Python Ecosystem and Virtual Environments","lvl2":"Python Virtual Environments"},"content":"","type":"content","url":"/environments#python-virtual-environments","position":7},{"hierarchy":{"lvl1":"The Python Ecosystem and Virtual Environments","lvl3":"What is a Virtual Environment?","lvl2":"Python Virtual Environments"},"type":"lvl3","url":"/environments#what-is-a-virtual-environment","position":8},{"hierarchy":{"lvl1":"The Python Ecosystem and Virtual Environments","lvl3":"What is a Virtual Environment?","lvl2":"Python Virtual Environments"},"content":"A virtual environment in Python is a self-contained directory that encapsulates a specific Python interpreter along with its associated libraries and scripts. It allows you to create isolated environments for different projects, each with its own set of dependencies, without affecting the system-wide Python installation.","type":"content","url":"/environments#what-is-a-virtual-environment","position":9},{"hierarchy":{"lvl1":"The Python Ecosystem and Virtual Environments","lvl3":"Why Use Virtual Environments?","lvl2":"Python Virtual Environments"},"type":"lvl3","url":"/environments#why-use-virtual-environments","position":10},{"hierarchy":{"lvl1":"The Python Ecosystem and Virtual Environments","lvl3":"Why Use Virtual Environments?","lvl2":"Python Virtual Environments"},"content":"When working on multiple projects, each with its own set of dependencies, managing packages can become challenging. Virtual environments provide an isolated space for each project, allowing you to avoid conflicts between different project requirements. Code in pacakges and libraries can often change with new releases and versions, so it’s important to work in environments to keep track of your Python version and the versions of the external packages you use.\n\nNote\n\nIt is always a good idea to create a new environment when you are starting a new research project, installing a particularly complex code that has a lot of dependencies, or developing your own piece of software.\n\nExercise One: Make an Environment\n\nIn your shell/terminal, writeconda create -n astro-rps python=3.9 numpy scipy matplotlib astropy pandas jupyterlab ipython ipykernel nb_conda_kernels\n\nThis line creates as conda virtual environment called astro-rps. When you run this, you will eventually get a prompt asking for a Y/n input; type Y and hit enter.\n\nWhat this commmand does is create a new environment with the name you give it. We’ve specifically told it to use Python 3.11. We’ve also given it a list of packages that can be installed via conda; I chose these because they are universally useful in astronomy and we will need them anyway. You can specify their versions here, as we did for python, but for now, we just want the latest versions.\n\nExercise Two: Activate Your Environment\n\nOnce your environment is created, you’ll see instructions for “activating” it. Follow them, e.g.,conda activate astro-rps\n\nOnce inside the environment, you should see its name on the left hand side of your terminal prompt, in parenthesis. Lets install a few more things, but this time, using pip, the standard python package installerpip install tqdm \npip install astroquery\n\nInstalling Individual Pacakges: Conda vs. Pip\n\nWhen do we install a package using conda, and when do we use pip? This is a bit messy, but in general, I suggest checking first if a conda version of the package is available. If it is, try installing via conda first. If not, or if that fails, then fall back on using pip (Inside your environment of course!). Using pip inside an environment will still mean you are only installing to that environment, but some of conda’s ways of measuring package dependencies and compatibility don’t extend to things installed with pip. Generally, we create environments with the “big things” installed with conda (as above), then install smaller, or pip-only things, inside with pip.","type":"content","url":"/environments#why-use-virtual-environments","position":11},{"hierarchy":{"lvl1":"First Python Codes"},"type":"lvl1","url":"/first-python-codes","position":0},{"hierarchy":{"lvl1":"First Python Codes"},"content":"Last week, we focused on how to navigate the Terminal, and set up our environments from which we can run Python. This week, we’re going to actually run Python. By the end of this part of today’s lesson, you will be able to...\n\nRun Python interactively through the Terminal\n\nCreate, edit, and run .py “scripts”: saveable, reproducible Python codes\n\nUnderstand and demonstrate the basic use of the print() function\n\nWrite and run your own classic “Hello World!” Python script\n\nWrite a multi-line Python script and understand basic program layout\n\n","type":"content","url":"/first-python-codes","position":1},{"hierarchy":{"lvl1":"First Python Codes","lvl2":"A Quick Reminder"},"type":"lvl2","url":"/first-python-codes#a-quick-reminder","position":2},{"hierarchy":{"lvl1":"First Python Codes","lvl2":"A Quick Reminder"},"content":"\n\nLast week, we set up conda environments that we’ll be using for the whole Astro-RPS series. Before we move forward, you’ll want to move into your “working directory” where you’ve been working on everything up till now (reminder: you can use cd [dirname] to navigate to your working directory from within the terminal). Once you’ve done that, activate the astro-rps environment:conda activate astro-rps\n\nNow, you can activate Python in the same terminal by simply typing:\n\npython\n\nor equivalently,\n\npython3.8\n\nIf things work properly, you should see a message that includes a few details about the Python version you are running, your operating system, etc. If you do, you should see a blinking cursor ready for you to type code in, often preceded by a >>>. From here, we should already be able to do some basic calculations.\n\nExercise One: Basic Mathematical Operations\n\nIn your shell/terminal where you have started up Python, try adding two numbers as below:10 + 2\n\n(hit enter when you’re done typing). This should return a single number. Then, tryprint(10+2)\n\nagain, hit enter. Is the output the same, or different? What happens when you swap out the + with “-”, then “/”, then “*”. What do each of these return?\n\nLastly, try:print(10 / 0)\n\nWhat happens?\n\nNow, in the same terminal, typeexit()\n\nand hit enter. Once you’ve done so, congrats! You’ve started, written, completed, and quit your first Python session.\n\nFrom here on, we actually will not recommend you use just “python” and instead recommend:   ipython\n\nThe differences are mostly unimportant, but it has some conveniences (like colored text for different keywords) that make it nicer to use.\n\nRunning Python Interactively in the Terminal vs. “Scripting”\n\nWhen we run Python interactively like we did above, then quit, none of the operations and outputs are saved. While you can sometimes use the up arrowkey to see recent commands and perhaps re-run them that way manually, this this obviously isn’t the way most codes are written: we normally care a lot about saving our work so that we can expand upon it later and re-run. So, in short, don’t do work in interactive Python sessions that you want to preserve later.\n\nWhat do we instead? We create scripts. This is just a fancy way of saying “codes that we save in files”. In Python, these have the file extension .py, i.e., you might call your script “code.py” (or hopefully something more descriptive).\n\nTo create a script, first exit Python. This should you leave in a normal bash shell, from which you can type\n\ntouch first_script.py\n\nThe command “touch” simply creates a basic text file with the name provided afterwards (here, first_script.py). We are now free to edit this file through whatever means we want: for now, open it up in whatever text editor you prefer (e.g., TextEdit, Notepad, Text Editor for Mac, Windows, and Linux respectively).\n\nNow, try adding print(\"Hello World!\")\n\ninto that file and save it. Then, open up a bash terminal (don’t type python) and typepython first_script.py\n\nfrom within the same directory where you saved the file. If you’re in the right place, your bash shell should print out the words Hello World. If you run into an error, check first that you’re in the right directory (and if not, use cd to get there).\n\n","type":"content","url":"/first-python-codes#a-quick-reminder","position":3},{"hierarchy":{"lvl1":"First Python Codes","lvl2":"Comments"},"type":"lvl2","url":"/first-python-codes#comments","position":4},{"hierarchy":{"lvl1":"First Python Codes","lvl2":"Comments"},"content":"\n\nWhat if we want to put something into the code that we don’t want to run? In that case, we can comment lines using the #. For our script above, we could add a description of what the code is doing as follows:\n\n # This is a program to print the words Hello World.\n print(\"Hello World!\") # this is the line that does the printing.\n\nAs can be seen, anything after the hashtag is completely ignored by Python.  This is true whether you’ve put the commented phrase on its own line or at the end of another line.\n\nThere’s not much more to comments than this! Broadly speaking, commenting is vital piece of making sure codes are understandable. We encourage you to include comments throughout your codes that indicate what important lines are doing. This will help avoid the situation where you log on a week later and totally lose the train of thought that you had the previous week (speaking from experience, we promise this really will happen).\n\n","type":"content","url":"/first-python-codes#comments","position":5},{"hierarchy":{"lvl1":"First Python Codes","lvl2":"Writing Multi-line Programs"},"type":"lvl2","url":"/first-python-codes#writing-multi-line-programs","position":6},{"hierarchy":{"lvl1":"First Python Codes","lvl2":"Writing Multi-line Programs"},"content":"\n\nWith the basics down, we can start to complexify. In Python, distinct commands are separated onto different lines. In most situations, Python is linear: lines are executed from the top to the bottom. To see this for a case when you want to print two different things, you can write the code:# This code prints a phrase and a number.\nprint(\"Hello World!\")\nprint(5+5)\n\nEach print statement has an implicit (but hidden) command at the end that tells it to move to the next line after printing, so you should find that this prints out each result on its own line. If you don’t want that, one choice of syntax to avoid that is:\n\nprint(\"Hello World!\", 5+5)\n\nwhere all we’ve done is separate the things we want by commas. As we’ll later discuss, print() is what we call a function that can take any number of arguments (things inside the parantheses).\n\nDoes the spacing and layout of the script file matter?\n\nYes and no. In general, “vertical” spacing in Python does not matter - you can feel free to hit enter as many times between the lines in your .py file. The number of spaces within the middle of a line also doesn’t matter, so print(5 + 5) yields the same result as print(5        +      5). However, horizontal aligment does matter. Lines should generally all start at the same left-justification, unless you are working with if statements, loops, or creating your own functions (more on each of those later). Let’s try to write a very simple code to demonstrate this.\n\nExercise Two: Testing Python Spacing Rules\n\nIn your first_codes.py file, add a tab or some spaces before the start of the second line:print(\"Hello World!\")\n    print(5+5)\n\nWhen you try to run this script, you should find that “Hello World” does not print. Instead, you will get an IndentationError - telling you that Python expected the second line to be left-aligned with the first line. You might wonder: why does the first line not work, even if the error is on the second line?\n\nThe short answer is that Python does a quick check before running your code to see if there any obvious bugs. This procedure is not quite as robust as in some other programming languages, and it won’t catch things like DivideByZero errors, infinite loops, etc. However, it will raise an immediate error if it seems things like unusual spacing or undefined variables (more on the latter in the next notebook).  Thus, for the example above, the error is raised before the first line of code is actually run, breaking the program flow.\n\n","type":"content","url":"/first-python-codes#writing-multi-line-programs","position":7},{"hierarchy":{"lvl1":"First Python Codes","lvl2":"What if we want to store information between lines?"},"type":"lvl2","url":"/first-python-codes#what-if-we-want-to-store-information-between-lines","position":8},{"hierarchy":{"lvl1":"First Python Codes","lvl2":"What if we want to store information between lines?"},"content":"\n\nThus far, we’ve only done a very simple set of computations and immediately printed the result. What if we instead wanted to store the result of that calculation for later? In that case, we will want to define a variable. It’s best to see this by example:\n\nresult = 5 + 5 \nprint(result)\n\nHere, we have stored the result of the 5+5 . We could have named “result” anything we wanted - you’re free to choose the name (within certain rules - e.g., t can’t start with a number). In this context, the = sign acts as a so-called “assignment operator”: it takes whatever is on the righthand side and stores it in whatever we have called the variable on the lefthand side. It has nothing to do with equalities or truth/falsity.\n\nWe now have everything we need to write our first useful Python program. Let’s use an example from astrophysics:\n\nExercise Three: The Stefan-Boltzmann Law\n\nCreate a new code file called “SB.py”. Within SB.py, write the necessary code to calculate the Luminosity (L) of a star according to the Stefan-Boltzmann law,L = 4\\pi R^2 \\sigma T^4\n\nIn doing so, define a unique variable for each of L, pi, sigma, R, and T (where the latter are radius and temperature); don’t just put the computation in a print statement. Using pi = 3.14 and sigma = 5.67 * 10^{-8} \\rm \\ W/m^{2}/K^{4},\nwhat is the luminosity of a star with R = 7 * 10^8 meters and T = 5776 K? You can assume the units work out (and therefore you can ignore them in Python). Hint: use the ** to use powers in Python, e.g., 2 ** 3 will give you 8.\n\nPrint L and compare your value to the Solar luminosity, 3.8 * 10^{26} Watts. Is your value greater, less than, or equal to the Solar luminosity?","type":"content","url":"/first-python-codes#what-if-we-want-to-store-information-between-lines","position":9},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!"},"type":"lvl1","url":"/hunt","position":0},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!"},"content":"","type":"content","url":"/hunt","position":1},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl2":"Introduction"},"type":"lvl2","url":"/hunt#introduction","position":2},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl2":"Introduction"},"content":"Welcome to the Unix Scavenger Hunt! This activity is designed to help you explore and become more comfortable with Unix commands. Each prompt is a mini adventure where you’ll use the terminal to accomplish specific tasks. Feel free to try the challenge in any order!","type":"content","url":"/hunt#introduction","position":3},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl2":"Rules"},"type":"lvl2","url":"/hunt#rules","position":4},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl2":"Rules"},"content":"You can use Google and other resources to find the commands and solutions, but try using man and -h first to see if the documentation makes sense!\n\nMake sure to write down/document the commands you use and what those commands do. We will go around and share what we learned at the end of the class time.\n\nTry to stick to terminal - don’t use your machine’s GUI to get to the solutions!\n\nHave fun and enjoy the exploration!\n\nOne General Tip!\n\nThe man command (stands for manual) prints detailed help information for unix commands and can help you throughout this exercise! You can call up the manual for a command like so: man ls. This opens a vim like editor that you can scroll through (with your mouse or arrow keys depending on your terminal set up). To exit the manual, press q.\n\n","type":"content","url":"/hunt#rules","position":5},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl2":"Scavenger Hunt Challenges"},"type":"lvl2","url":"/hunt#scavenger-hunt-challenges","position":6},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl2":"Scavenger Hunt Challenges"},"content":"We are sharing a folder with all of you via Slack. Everyone should download a copy of this folder onto their machine for this exercise.\n\n","type":"content","url":"/hunt#scavenger-hunt-challenges","position":7},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl3":"Challenge 1: The Hidden Treasure","lvl2":"Scavenger Hunt Challenges"},"type":"lvl3","url":"/hunt#challenge-1-the-hidden-treasure","position":8},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl3":"Challenge 1: The Hidden Treasure","lvl2":"Scavenger Hunt Challenges"},"content":"Find a file named “treasure.txt.” Navigate to it, retrieve the contents of the file, and share what you’ve discovered!\n\nOpen for Hint\n\nHere are some ideas:\n\nConsider the grep command!\n\nYou can use cat, less, or more to view the contents of a file. Like for man, close the opened program by hitting q.\n\nHard Mode: try using an editor like vim or nano to read the file!\n\n","type":"content","url":"/hunt#challenge-1-the-hidden-treasure","position":9},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl3":"Challenge 2: Mysterious Sizes","lvl2":"Scavenger Hunt Challenges"},"type":"lvl3","url":"/hunt#challenge-2-mysterious-sizes","position":10},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl3":"Challenge 2: Mysterious Sizes","lvl2":"Scavenger Hunt Challenges"},"content":"Try to find the directoy with the biggest size in the folder we shared with you. Now try to find the largest individual file. Share the directory name (and/or file name), size, and the command you used to find it.\n\nOpen for Hint\n\nHere are some ideas:\n\nLook into available flags for the ls command\n\nConsider the du command, and play around with which flags you can use!\n\n","type":"content","url":"/hunt#challenge-2-mysterious-sizes","position":11},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl3":"Challenge 3: The Time Traveler","lvl2":"Scavenger Hunt Challenges"},"type":"lvl3","url":"/hunt#challenge-3-the-time-traveler","position":12},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl3":"Challenge 3: The Time Traveler","lvl2":"Scavenger Hunt Challenges"},"content":"Find a file with a modification date that is at least one month ago and change its timestamp!\n\nOpen for Hint\n\nHere are some ideas:\n\nRecall we can us ls -l to view file details\n\nConsider the touch command!\n\n","type":"content","url":"/hunt#challenge-3-the-time-traveler","position":13},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl3":"Challenge 4: The Artist","lvl2":"Scavenger Hunt Challenges"},"type":"lvl3","url":"/hunt#challenge-4-the-artist","position":14},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl3":"Challenge 4: The Artist","lvl2":"Scavenger Hunt Challenges"},"content":"Create a new directory named “masterpiece” and populate it with text files, each containing a line from your favorite quote or poem. Use an editor (either vim or nano, but I recommend vim!) to make your files. Share the commands you used to create and populate the directory.\n\nThen, use a command to print out all your lines of poetry (across the files) one after the other.\n\nOpen for Hint\n\nHere are some ideas:\n\nUtilize commands like mkdir to create folders. You can use vim to generate files!\n\nConsider the cat command to print your poems!\n\nFor printing all lines, there is a way with both grep and head, both of which use the wildcard *!\n\n","type":"content","url":"/hunt#challenge-4-the-artist","position":15},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl3":"Challenge 5: Pipe Explorer","lvl2":"Scavenger Hunt Challenges"},"type":"lvl3","url":"/hunt#challenge-5-pipe-explorer","position":16},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl3":"Challenge 5: Pipe Explorer","lvl2":"Scavenger Hunt Challenges"},"content":"Navigate to a directory containing multiple text files. Use a combination of commands and piping to find and count the number of lines in each text file. Share your results, showing the filename and the corresponding line count for each text file.\n\nOpen for Hint\n\nHere are some ideas:\n\nConsider using find to locate text files and wc -l to count lines.\n\n","type":"content","url":"/hunt#challenge-5-pipe-explorer","position":17},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl2":"Conclusion"},"type":"lvl2","url":"/hunt#conclusion","position":18},{"hierarchy":{"lvl1":"Unix Scavenger Hunt!","lvl2":"Conclusion"},"content":"Remember, the goal is to have fun and gain hands-on experience with Unix commands. Feel free to experiment and explore beyond the prompts. Happy scavenger hunting!","type":"content","url":"/hunt#conclusion","position":19},{"hierarchy":{"lvl1":"Calculating the Luminosities of Stars"},"type":"lvl1","url":"/week2-assignment","position":0},{"hierarchy":{"lvl1":"Calculating the Luminosities of Stars"},"content":"Now, we can put together everything we’ve learned so far to build a useful script.  We’ll do so in the context of the properties of stars.\n\n1. The Stefan-Boltzmann Law\n\nStars, to zeroth order, can be considered spherically-symmetric blackbodies. Under those conditions, their luminosities can be computed via the Stefan-Boltzmann law,L = 4\\pi R^2 \\sigma T^4\n\nwhere R is the radius, T is the effective temperature of the Star, and σ is the Stefan-Boltzmann constant, \\sigma = 5.67 * 10^{-8} \\rm \\ W/m^{2}/K^{4}.\n\nThe goal of today’s lab is to implement this in Python, i.e., write a code to calculate the Luminosity (L) of a star according to the formula described above. The rough steps are as follows:\n\nCreate a new code file called “SB.py” using the Terminal.\n\nWithin SB.py, define a unique variable for each of π, σ, R, and T. For now, assume \\pi = 3.14, R = 7 * 10^8 meters and T = 5776 K.  You can assume the units work out (and therefore you can ignore them in Python).\n\nUsing basic mathematical operations, compute the value of L according to the formula above using the variables you just defined. Store the result in a new variable. (Hint: powers in python are implemented via the ** operator, e.g., 6**2 = 36)\n\nUsing f-strings, print the result in a sentence that looks like:\nThe Luminosity of a star with effective temperature [value of T] and radius [value of R] is [value of L].\n\nTest the script by running it from the terminal. Outside of Python, compare your luminosity value to the Solar luminosity, 3.8 * 10^{26} Watts. Is your value greater, less than, or equal to the Solar luminosity?\n\nRather than simply hardcoding the value of T and R in your script, use the input() function to allow you to provide the values in the terminal at runtime.\n\nImplement the comparison to the Solar Luminosity in your code and store the result a new boolean (True/False) variable called supersolar. Then extend your f-string above to print whether the star is more luminous than the Sun. The output should look like: The Luminosity of a star with effective temperature [value of T] and radius [value of R] is [value of L]. It is [value of supersolar] that this is more luminous than the Sun.\n\n2. Practice with List Indexing\n\nLet’s imagine you have data for bright stars that looks a bit like:star_names = [\"Sirius\", \"Canopus\", \"Rigil Kentaurus\", \"Arcturus\", \"Vega\", \"Capella\", \"Rigel\", \"Procyon\", \"Achernar\", \\ \n\"Betelgeuse\", \"Acrux\", \"Altair\", \"Aldebaran\", \"Spica\", \"Antares\", \"Pollux\", \"Fomalhaut\", \"Deneb\", \"Regulus\", \"Adhara\"]\n\nstar_temperatures =  [9940, 7400, 5800, 4300, 9600, 4900, 12100, 6550, 14600, 3500, 28000, 7700, 3900, 22200, 3400, 4940, 8550, 8525, 12300, 20800]\n\nstar_radii = [1.711e9, 7.8e8, 1.227e9, 2.785e9, 2.364e9, 1.192e9, 7.6e8, 7.43e8, 1.586e9, 9.52e10, 6.01e9, 1.656e9, \\ \n4.28e9, 7.739e8, 8.12e9, 1.927e9, 1.834e9, 8.48e9, 3.919e9, 4.66e9]\n\nCreate a new script called star_calcs.py.\n\nUsing indexing, figure out: what the name of the tenth star in this list? Then, store the index in a variable.\n\nNow, using the stored index, isolate the temperature of the star by accessing the appropriate element of the second list.\n\nRepeat step 2 for the radius.\n\nBy copy-pasting your formula implementation from exercise 1 into your new script, compute the luminosity of the star of the tenth star.\n\nNow that we’ve finished with star 10, let’s try to make it our code more generally applicable.\n5. Have your program take an index in via input() and run the calculation for the star corresponding to that index.\n6 (BONUS): Create a dictionary for each of the two properties for the first 5 stars above (that is, a dictionary for radius and a dictionary for temperature). The keys should be the star names.\n7 (BONUS part 2): Now have your program take the star name as an input and print the name, temperature, radius, and computed luminosity in a nicely formatted sentence.","type":"content","url":"/week2-assignment","position":1},{"hierarchy":{"lvl1":"Week 3 Assignment"},"type":"lvl1","url":"/assignment-w3","position":0},{"hierarchy":{"lvl1":"Week 3 Assignment"},"content":"The main goal this week is to get familiar with importing (and using) three really useful packages: numpy, astropy and matplotlib. Throughout the assignment we will also write some for-loops and practice logic statements\nThis assignment is meant to be done in groups of 2-3 people.\n\n","type":"content","url":"/assignment-w3","position":1},{"hierarchy":{"lvl1":"Week 3 Assignment","lvl2":"Part 1: Loading in the SubHalo Merger Tree Data (10 - 15 minutes)"},"type":"lvl2","url":"/assignment-w3#part-1-loading-in-the-subhalo-merger-tree-data-10-15-minutes","position":2},{"hierarchy":{"lvl1":"Week 3 Assignment","lvl2":"Part 1: Loading in the SubHalo Merger Tree Data (10 - 15 minutes)"},"content":"All galaxies live inside large accumulations of dark matter. These accumulations can be thought of as clouds or “halos”.\nA “merger tree” is a way of understanding the accretion history of a dark matter host halo. The trunk represents the present day host halo, and every branch is a merger event (a smaller halo being eaten up).\nThe higher up the tree you go, the further back in time you look! I work with a code named SatGen that can create these merger trees and today you will be handling the output of the SatGen code.\n\nThe code outputs several numpy arrays that are compressed together into a single .npz file.\n(See this link \n\nhttps://​numpy​.org​/doc​/stable​/reference​/generated​/numpy​.savez​.html)\n\nStep 1\n\nDownload the tree_0.npz file from slack (or however we share it with you). Create a new script in your IDE (VSCode, PyCharm, etc). You will want to be saving your code in this script throughout this assignment, but you may also want to have an ipython instance open, for the purposes of writing and testing code quickly before copying it into your script.\n\nOpen the .npz file in your code.\n\nHow many arrays are contained in the compressed data file?\n\nSelect the mass array and print out its dimensionality.\n\nWhat about the time array?\n\nHint: Opening the File + Looking Inside\n\nAn .npz file is a file type defined by the numpy package. Look into the numpy package to see how you can open that file type in python. Once you have the file open in python, you need some way to figure out what it contains. Recall that in dictionaries data is stored in key: value pairs, where keys represent that names. This type of numpy file is similar. In order to figure out what the names of our arrays are, we need to use the .keys() method.\n\nHint: Figuring out Dimensionality\n\nLook into using the shape attribute to figure out the dimensionality of a numpy array.\n\nStep 2\n\nDiscuss in your groups what physical units might make sense for these values. How can we add this information to the data which is currently only made up of float values?\nUsing astropy.units create two new arrays (one for time and one for the mass) that have the proper units.\n\nHint\n\nIn astronomy, we often use the mass of the Sun as our mass unit and we often use gigayears as our time unit. Try to set the units of your mass and time numpy arrays to these using astropy.units.\n\nStep 3\n\nYou might be familiar with the kilogram, meters, seconds (KMS) standard for units.\nConvert your mass array into kg using astropy.units.\nConvert your time array into seconds.\nDo you see why it is useful for astronomers to work with other units?\n\n","type":"content","url":"/assignment-w3#part-1-loading-in-the-subhalo-merger-tree-data-10-15-minutes","position":3},{"hierarchy":{"lvl1":"Week 3 Assignment","lvl2":"Part 2: Playing around with halo mass (10 - 15 minutes)"},"type":"lvl2","url":"/assignment-w3#part-2-playing-around-with-halo-mass-10-15-minutes","position":4},{"hierarchy":{"lvl1":"Week 3 Assignment","lvl2":"Part 2: Playing around with halo mass (10 - 15 minutes)"},"content":"\n\nNow that you have opened up the data, I can tell you that the host halo is saved in the first index of the mass array.\nThe rest of the indices correspond to the subhalos that were accreted by the host during the “simulation”.\n\nStep 4\n\nFind the maximum mass of every subhalo across cosmic time! To start, you can try just finding the maximum mass for one subhalo (for ex. the first subhalo stored as the first element of the mass array).\n\nTry this using a for-loop, then disuss with your group if there is a more efficient way accomplish the same thing.\n\nTIP\n\nDark matter halos are REALLY massive! The SatGen code saves these mass values in units of solar masses and as you see, most halos are larger than 1 million solar masses.\n\nIt might make more sense to work with these numbers in log10 space. When you try to convert these values into log10 space, you might encounter a UnitTypeError. See if you can figure out what this error is telling you by referencing the astropy units documentation.\n\nHint: Debugging UnitTypeError\n\nWhen using astropy.units we are actually converting our data from float datatype to what’s called an astropy Quantity datatype. In order to do mathematical operaitons, we usually need to convert our data back to a regular type like float. The way we can do this is by using the .value attribute of an astropy Quantity. So, we can convert our entire mass array back into regular old floats using mass.value.\n\nSideNote: if you do some unit conversions to your mass array while it is in Quantity datatype form, then convert it back to a regular numpy array, the actual values are still converted! You can see this for yourself by using astropy to convert to kg, then using .value to convert that back to floats. The values will still be changed! This is why the astropy.units module is so useful. You will never have to worry about unit conversions again.\n\nStep 5\n\nNow, we are going to make our very first plot! We will be using a python package called matplotlib. The matplotlib documentation has a nice page to walk you through the basics of how we can use this package to make plots. This will be a helpful reference: \n\nMatplotlib Tutorial\n\nPlot a histogram of the maximum masses you computed using the matplotlib.pytplot.hist method (See \n\nthis link).\nMake sure to label the axes and change the binsize so that we have 15 evenly spaced (in log space) bins and put the y axis in log scale!\n\nTIP\n\nYou could have also accomplished something similar with numpy.histogram but since we wanted to visualize the data, in this case its easier to use matplotlib\n\nWOW! There are so many more low mass subhalos than there are high mass subhalos!! LCDM predicts a steep mass function!\n\n","type":"content","url":"/assignment-w3#part-2-playing-around-with-halo-mass-10-15-minutes","position":5},{"hierarchy":{"lvl1":"Week 3 Assignment","lvl2":"Part 3: Plotting the merger tree! (20-25 minutes)"},"type":"lvl2","url":"/assignment-w3#part-3-plotting-the-merger-tree-20-25-minutes","position":6},{"hierarchy":{"lvl1":"Week 3 Assignment","lvl2":"Part 3: Plotting the merger tree! (20-25 minutes)"},"content":"\n\nStep 6\n\nFirst, let’s plot just the host halo’s mass vs. time. Start by selecting the host halo (e.g. the first element of in the mass array), and plot mass vs. time using matplotlib.\n\nHint: Plotting 2-D Data\n\nYou can use matplotlib.pyplot.plot to plot a line by giving the arguments (x-data, y-data).\n\nOkay so as we know, there are a bunch of subhalos in this merger tree.\nIf we wanted plot all of them with respect to time, the figure would be a bit crowded. Instead lets only pick the ones that are above a given mass at present day.\n\nStep 7\n\nIn your mass array, select only the present day time index. Create a mask on this selection that excludes an subhalos that are less massive than 10^9.5 solar masses.\nHow many are there?\n\nStep 8\n\nMake a mass vs. time plot for the subhalos that meet the present day mass criteria in the previous step.\nMake sure you plot the host mass in a different color.\nDon’t forget to label your axes!\n\nCan you see the little dips in the accretion histories? That is when the subhalo is accreted onto the host! Notice there is no such dip for the red line!","type":"content","url":"/assignment-w3#part-3-plotting-the-merger-tree-20-25-minutes","position":7},{"hierarchy":{"lvl1":"Week 4 Exercises"},"type":"lvl1","url":"/week4","position":0},{"hierarchy":{"lvl1":"Week 4 Exercises"},"content":"In this set of exercises, you’ll get more practice writing routines in Python and working with numpy arrays, lists, and dictionaries.\n\nExercise 1: Minimum Maximum\n\nCreate a script minmax.py.\n\nIn this script, the first line (after importing numpy) should define a list, input_list.\n\nBelow that, write code to perform the following logic:\n\nCreate a list containing the minimum and maximum of the list, e.g., [listmin,listmax].\n\nAdd a variable below your list_input definition, but above the logic in (1). Call it positive_only, and assign it an initial value of False.\n\nNow modify your code logic --- if positive_only is True, have it return the min and max of only the subset of the input list that has positive values. If there are no positive values, your output list should be[None,None]. If only one value in the input is positive, it should return the same number twice.\n\nYou may find it useful to use some if-statements, some list indexing, and the np.min/np.max functions.\n\nExercise 2: Finding Peaks\n\nCreate a script peak_finder.py.\n\nThe goal of this script is to locate the peaks in an array. In this case, it will be a 1D array, but this issue generalizes: stars in an image are peaks, and we often need to find them!\n\nBelow, I provide a list, flux_values, and then I plot it’s y values. Note that matplotlib assumes x-values are an arange if not provided. Your goal is to write code which can find the peaks in this array, where a peak is defined as any location where the flux value is higher than both neighboring values (i.e., in [1,2,1], index 1 (the two) would be a peak).\n\nThe answer you are looking for (see the plot) is [4,13,16]. In an array this small, you could find this by eye or trial and error, but in a real array of thousands of elements, you may find it useful to have a peak finding code around!\n\nHint\n\nThere is a looping based solution to this, and a non-looping based solution! If you ARE looping, you may need to be careful about how you handle the endpoints.\n\nimport numpy as np \nimport matplotlib.pyplot as plt \n\n\nflux_values = [0,0,1,2,3,2,1,1,1,0,2,2,3,5,4,3,6,2,1,0]\n\nfig,ax = plt.subplots()\nax.plot(flux_values)\nax.axvline(4,alpha=0.2)\nax.axvline(13,alpha=0.2)\nax.axvline(16,alpha=0.2)\n\nExercise 3: Load an Astronomical Image\n\nIn this exercise, we’ll view our first astronomical image! You can find it on Slack.\n\nTo open an astonomical image, we will use the astropy.io.fits module. Import it:from astropy.io import fits\n\nTo obtain the header and image data from this file, we can do the followingwith fits.open('/path/to/file') as hdu:\n    header = hdu[0].header \n    image = hdu[0].data\n\nWe’ll talk more about what this means on Monday!\n\nOnce you’ve done this, you should have an image variable that is a 2D array. Use the imshow() command from matplotlib to view it.\n\nDoes it look like much?\n\nYou will probably need to adjust key parameters vmin and vmax to get a nicer looking image. I suggest using np.percentile() to compute the 1st and 99th percentile of the data, and then use those values when seeting the vmin and vmax arguments in imshow.","type":"content","url":"/week4","position":1},{"hierarchy":{"lvl1":"Functions (and HII regions in M33)"},"type":"lvl1","url":"/assignment-functions","position":0},{"hierarchy":{"lvl1":"Functions (and HII regions in M33)"},"content":"In this week’s lab, we’ll see how to construct and use Python functions in practice, using a narrowband image of the galaxy M33 as our dataset.\n\nOur ultimate goal will be to nicely plot and crop our image to make scientific measurements of the physical size of certain features in the galaxy.\n\nWe’ll also see at the end why writing functions was a useful way to organize and carry out this analysis. We’ll start focusing just on the image. In Part II, there is a scientific overview regarding HII regions and why we are interested in them.\n\n# Some libraries we'll need throughout\nfrom astropy.io import fits \nfrom astropy.wcs import WCS \nimport numpy as np \nimport matplotlib.pyplot as plt\n\n","type":"content","url":"/assignment-functions","position":1},{"hierarchy":{"lvl1":"Functions (and HII regions in M33)","lvl2":"Part 0: Warm up"},"type":"lvl2","url":"/assignment-functions#part-0-warm-up","position":2},{"hierarchy":{"lvl1":"Functions (and HII regions in M33)","lvl2":"Part 0: Warm up"},"content":"Before we dive into new things, let’s re-familiarize ourselves with how to write some simple functions.\n\nExercise 0\n\nTake your code from last week --- the minmax script and peak_finder script, and turn them into functions,which take in the relevant inputs and return the answers. Show that you can use your functions on multiple inputs! For your minmax code, you should set the positive_only flag as an argument with a default value.\n\n","type":"content","url":"/assignment-functions#part-0-warm-up","position":3},{"hierarchy":{"lvl1":"Functions (and HII regions in M33)","lvl2":"Part 1: Loading and viewing astronomical images"},"type":"lvl2","url":"/assignment-functions#part-1-loading-and-viewing-astronomical-images","position":4},{"hierarchy":{"lvl1":"Functions (and HII regions in M33)","lvl2":"Part 1: Loading and viewing astronomical images"},"content":"Astronomical images (those taken at a telescope like Keck Observatory, or in space, like HST or JWST) are, at their core, a 2D array of values. In general, we take images in one band (color) at a time, and if we want color images like those you can take with a camera, we have to later combine those images.\n\nThe vast majority of astronomical images that have been, and continue to be, taken are stored in a special file format called FITS. Fits stands for Flexible Image Transport System. It’s a binary format which requires specialized programs to open. One is SAOImage DS9, a GUI based tool I recommend having if you will be working with astronomical images.\n\nIn Python, we can use the astropy.io.fits module to load the header (a dictionary of information about the file) and data (images) from a FITS file.\n\nNote\n\nWhile FITS files are primarily images, it is also possible to store tables of data in FITS format; you’ll see this in upcoming weeks.\n\nWithin a FITS file, information is stored in what are called extensions. These are like separate buckets/folders, and thus allow one to store multiple images, or an image + table, or multiple tables, within 1 file. But usually, we have a simple file with 1 image in the 0th extension, and its header.\n\nWhen we load a FITS file, we usually also want to know something about the coordinates (on the sky, so RA and DEC) of the things in our image. To do this, we need to know the WCS (world coordinate system) coordinates of the image. The information needed to make one of these is in the image header, and there is an astropy function to convert a header to a wcs object.\n\nThe code below will load the M33 image we’ve provided into Python, setting the 2D array im as the image, and the wcs object via the astropy routine.\n\nfrom astropy.io import fits \nfrom astropy.wcs import WCS \n\nwith fits.open('./M33_halpha.fits') as hdu:\n    im = hdu[0].data \n    wcs = WCS(hdu[0].header)\n\nWe can, if we wish, encapsulate this operation into a function. It’s short enough that it’s not overly onerous to write out each time. But we can make these three lines into one, which might make our code easier to read when loading many different fits files throughout a script.\n\nExercise 1.1\n\nStart by defining a function load_fits which has arguments fname (str), and extension (int). These are the pieces of information we needed above.\n\nThen add these lines above into the function trading out the hard coded elements for the function arguments.\n\nFinally, return im, wcs. As the majority of fits image store the image in the 0th extension, you can set the default for that argument to 0.\n\nRemember!\n\nDon’t forget to document your function!\n\nExercise 1.2\n\nOne danger of our function above is that some fits image do not have any wcs information stored in their header. At current, we will throw an exception if we try to load such an image.\n\nAdd a try/except statement to your function around the wcs= line. Try loading a wcs as we did above, but if there is an exception, continue, and return the im (image pixels) and None for the wcs return. Optionally, print a message that this occurred.\n\nExercise 1.3\n\nUse your new load_fits function to read in the M33_halpha.fits file. Save the output of the function into the variables m33_im and m33_wcs.\n\nHint\n\nIf you get an error about fits or WCS, make sure you’ve imported those functions from astropy in your file!\n\nExercise 2.1\n\nLet’s visualize the image we have loaded.\n\nUse the matplotlib imshow command to plot the image. To see anything useful, you will need to set the vmin and vmax arguments --- a convenient choice is to compute the np.percentile of the data at [1,99] and to set those as the min and max scalings.\n\nAdditionally set origin='lower' and cmap='gray_r' in your imshow call.\n\nI suggest a figure size of 10 by 10 inches. Remember we can call fig, ax = plt.subplots() to make our figure and axes objects (so here, fig,ax=plt.subplots(figsize=(10,10))).\n\nExercise 2.2\n\nThis is already a few lines of code, and we often need to plot astronomical images. Let’s now make a function that can streamline some of these lines of code above for us.\n\nFirst define a function implot. The first argument should be a variable path_or_pixels. We’re going to allow users to either provide a file name to a fits file directly, or provide an image array (as we did above). To handle this, write some logic using the isinstance() python function to check whether the input is an array or a string, and if it is a string, use the load_fits function we wrote in Exercise 1 to load the image. (Otherwise, we’ll just set our image to be the path_or_pixels input, assuming it is an array. You could use isinstance() again to check if it is a numpy array and raise an exception if not, optionally.)\n\nInclude as arguments the following:\n\npercentiles (list) (which will let users scale vmin and vmax, set to a default of [1,99.5].\n\nfigsize (tuple): an optional argument with a default set to something like (8,8).\n\ncmap (str): argument with a default of 'gray_r', passed along the imshow command, giving us control over the plotting color mapping.\n\nYour function should return the fig and ax objects it created.\n\nHint: isinstance()\n\nIf you haven’t used isinstance() yet, here’s a primer.\n\nWhen we want to check the type of a variable, we can use type(var_name) to see its typename. When we want to check or ensure that a variable’s type matches some desired type, we can use isinstance(variable,type) to return True or False. For example, isinstance('test',str) would return true, because the input 'test' is a string. The names for the built-in types are str,bool,list,dict,tuple,float,int, etc. For a numpy array, its “type” is np.ndarray.\n\nHint\n\nWe haven’t covered how to type-hint multiple allowed types yet. Here’s a preview hint if you want to include it, but you don’t have to:from typing import Union \ndef func(arg: Union[np.ndarray,list]):\n    ...\n\nExercise 2.3\n\nTry out your function to make sure it is working as expected --- try inputting both our image array from above, as well as the file name. Try changing the percentiles and figsize and make sure the function responds accordingly.\n\nExercise 2.4\n\nNow we want to incorporate the wcs into the mix.\n\nNote\n\nA WCS object encapsulates the “world coordinate system”, which indicates where on the sky an image is pointed. You can think of these coordinates like latitude and longitude on Earth, but for the full sky. We’ll learn more about these objects later, but for now, know that a wcs object can be constructed from the fits file header (when the image has that information), and tells our plotting code how to map between a pixel position and a sky position under the hood.\n\nCurrently, a wcs will be accessible if the user provides the path to a file that has one. Now, add an optional argument to your function wcs with a default of None. Add logic so that if the wcs is not None (either from loading an image, or after the function input), we add the following to our subplots command:fig, ax = plt.subplots(figsize=figsize,subplot_kw={'projection':wcs})\n\nWhat this does is turn our regular axis into a WCSAxis, which can handle plotting astronomical units along the axes of our image.\n\nTry your function again, but this time add the wcs we created in the previous exercise. How do your plot axes change?\n\nExtra Feature (optional)\n\nAt the moment, the user chooses whether to provide a wcs for the pixels case, but we force a wcs plotting if a path to a fits file that contains a wcs is provided. This should be the default case, but it might be nice to give the option to turn that off. The easiest way to accomplish this is to add an ignore_wcs optional argument to your function which has a default of False. Thus, given an image file path, we can plot using coordinates by default, or the raw pixels by ignoring any wcs present. This works too if we provide a wcs but want to easily toggle it on and off.\n\nExercise 2.5\n\nTry out your function again, using both the fits file string and the array, but now try all your toggles --- i.e., fits file string, fits file string plus ‘ignore_wcs’ if you added that feature, array input, array input + wcs object input. Do you get the proper behavior? Below is an example of what the output should look like for default loading of the image.\n\nThere are now 13 lines of logic in our function, and hopefully it is becoming clear why making such a function is so useful --- we can now very quickly and easily load and plot any fits file, or any array we have on hand, with wcs on or off, with limits setting, all in one line.\n\nNote\n\nIt is a good idea to return the fig and ax objects at the end of our function. This is useful because if we want to add to our plot (say, add a circle somewhere, or text), or change our plot (adjust the limits, etc.) we need to be able to access those objects. As we learned when we discussed scope, anything from inside a function that we want access to after the function has been run must be returned back to the larger scope of the python script we are working in.\n\n","type":"content","url":"/assignment-functions#part-1-loading-and-viewing-astronomical-images","position":5},{"hierarchy":{"lvl1":"Functions (and HII regions in M33)","lvl2":"Part II: The Size of HII Regions"},"type":"lvl2","url":"/assignment-functions#part-ii-the-size-of-hii-regions","position":6},{"hierarchy":{"lvl1":"Functions (and HII regions in M33)","lvl2":"Part II: The Size of HII Regions"},"content":"The Science\n\nFor the rest of the assignment, we will be investigating the physical size of HII regions in nearby galaxy M33. Not sure what that means? Here’s a quick primer.\n\nStars form of many different masses (from much smaller than the sun to much larger), with many more low mass stars forming than massive stars^*. While very few high mass (e.g., 3-10+ M_{\\odot}) stars form at a time in a galaxy, they have an outsized effect, dominating the light of the low mass stars (though they live much shorter lives). They are also the only stars (dubbed O-type) who put out significant light in the ultraviolet part of the spectrum. We know that our own sun does emit some light in the UV (that’s the more high energy, dangerous light that can give us cancer, hence sunscreen), but these stars pump out most of their light in the UV.\n\nUV light has enough energy to ionize the atoms in gas (especially hydrogen gas), which means to knock the bound electron out of the atom and leave behind a proton and an electron. In some equilibrium, these electrons recombine with protons, and the electrons cascade through several energy levels as they fall toward the ground (most bound) state. For each gap they drop, the atom emits a photon with an equivalent energy to the difference between the levels traversed.\n\nThis process of recombination produces light at specific wavelengths, so when you look at planetary nebulae, star forming regions, or supernova remnanta (see below), the colors are representitive of the different elements and energy levels being traversed.\n\n\nThe Eagle Nebule, where we can see the hollow region being blown out by young stars (with the famous pillars of creation remaining, soon to be whittled down. Credit: ESO\n\nBright, young stars actually put out enough radiation to “blow out” and push on the gas remaining from the clouds from which they formed. This carves our roughly spherical regions known as Strömgen spheres, the inner boundary of which is usually lit up in this ionized emission. The size of the sphere blown out depends on the total amount of flux coming from the bright stars, which in turn depends on how many of them there are.\n\nIn our image of M33, we can see lots of these roughly spherical regions being highlighted by the narrow, Hα filter being used to observe the galaxy. By measuring their size in pixels and using our knowledge of the distance to M33, we can perform some simple trigonometry to determine their actual physical sizes. As a bonus, we can then roughly estimate the number of O-type stars responsible for the visible HII region. (note that Starforming region and HII region are roughly synonymous; HII is the chemical name for ionized hydrogen).\n\n*\n\nStars that form together out of one more massive cloud have masses drawn from what is called an initial mass function, or IMF, which is roughly exponential.\n\nExercise 3.1\n\nWhile we can see by eye lots of small HII regions scattered around M33 in our image, to do a more careful analysis of the sizes we will need a way to crop our images to just focus on one HII region at a time.\n\nThere are fundamentally two ways to carry out this crop. We can work in units of image pixels, and use array indexing and slicing to select subarrays containing out HII regions. Or, we could use our wcs objects to pick central coordinates on the sky and a size (in sky angular units) to crop in on, and use an astropy tool to do the crop.\n\nIn this exercise, we will work with the pixels, as it will be good practice for our array indexing and slicing.\n\nOur first step is actually determining the pixel coordinates of a given HII region. While there are more complex methods we could write, it is not so hard to do this by eye. That said, a simple crosshairs function would help us know that our chosen coordinates land right on an HII region.\n\nWrite a function crosshairs which takes in crosshairs(ax,x,y). It should then use ax.axvline(x) and similarly ax.axhline(y) for y to plot a crosshairs over our image at some coordinates. Return ax when done.\n\nRun you function for position (995,1445). Are you right on an HII region?\n\nExercise 3.2\n\nNow that we have a set of starting coordinates, we want to crop our image down to a certain window around our coordinates which contain the HII region.\n\nWrite a function crop_image which takes in the image array, (x,y) central coordinates, and a window size in pixels. Your functiuon should compute the half-window size (integer division of input window by 2), then index the image from the central coordinates +/- the half-window size. It should return the new image.\n\nUse your implot function to show a new image output by your crop_image function using the above coordinates and a window size of 50 pixels.\n\nHint\n\nRemember that arrays are indexed by row first, then column! This means in our bracket indexing, “y-value” indexing comes first, then “x-value” indexing.\n\n# Here is an an example of ~what you should be seeing\n\nExercise 3.3\n\nYou should hopefully now have a nice, circular feature filling most of your plotted image. This is our HII region!\n\nIn order to estimate its radius in pixels, we’d like to place a circle down that lines up with the ridge of emission defining the circle (and adjust our center as needed, as our by-eye estimate from the full image was likely not perfect.\n\nRecall that we can compute the x and y values of a circle with position (x_0,y_0) and radius R via x(\\theta) = x_0 + R\\cos(\\theta) and y(\\theta) = y_0 + R\\sin(\\theta). Write a function add_circle(ax,x,y,r) which takes in our image ax, creates an array of theta values from 0 to 2\\pi (Hint: np.linspace() is good for this), computes the arrays for the x and y positions of the circle based on its center and radius, plots them using ax.plot(x,y) over the image, and returns the ax.\n\nUse your function to determine the new center and radius R of this HII region.\n\nWarning\n\nWhen you crop from the full image to the zoom image, you have a new array with a new shape. Our original coordinates no longer matter; your x,y center is the center of the new array, which should have a shape of 50x50.\n\nSo starting with a center of 25,25 makes sense here. If you want to know what these coordinates refer to back in the original image, you’ll have to do a coordinate transformation to “uncrop” them --- calculate the coordinates of the left and bottom edge of the crop region and add the new center in x,y to those.\n\nWe don’t need to do that here, as we’re interested in R (which is preserved in the crop as the pixel scale has not changed), but not the precise x or y in original image coordinates.\n\nExercise 3.4\n\nNow that we have a measurement of R_{HII} in pixels, we need to begin converting this to a physical scale. We can do this because we know the pixel scale of our detector, that is, how many angular degrees (here we’ll use the arcsecond) on sky does one pixel subtend. For example, if we have a pixel scale of 2.2, that means each pixel subtends 2.2 arcseconds on sky (roughly 0.0006 degrees).\n\nWe can then make a triangle --- the long edge is the distance in physical units to M33. The short edge is the length we want, the physical radius of the HII region, and θ is our measured angular radius, obtained by multiplying the radius in pixels by the pixel scale.\n\nTo perform the actual trigonometric step, we need to compute D\\tan(\\theta).\n\nWrite a function compute_size(distance,s_pix,pixel_scale). Using the pixel scale, it should convert the size s_pix to arcseconds, then onward to degrees (there are 3600 arcseconds in a degree), then onward to radians for the trig function (np.deg2rad() may be useful here). Then, using that, compute the size using the formula above and return it. The size output will have units equal to the length units that were assumed for D.\n\nM33 has a distance of 0.869 Mpc (Megaparsec). Using your function, compute the radius of the HII region in parsec by converting the M33 distance to pc, then using your compute size function. Assume a pixel scale of 2.2. How big is this HII region?\n\nExercise 3.5 (Bonus)\n\nWe can avoid the annoyance of unit conversions by using the astropy.units library. Look up how to create astropy unit quantities, and rewrite your compute_size function to allow distance to be input in any unit, as well as the pixel scale. Then easily convert your output to pc at the end and return it.\n\nExercise 3.6\n\nNow that we know the physical size of the HII region (not a trivial feat!) we can actually go further. In a back-of-the-envelope sense, the radius of the full HII region can be approximated as that of a Strömgren sphere around a “single” high energy star.\n\nThe formula for this radius isr_S = \\left(\\frac{3N^*}{4\\pi\\alpha n^2}\\right)^\\frac{1}{3}\n\nwhere N^* is the ionizing photon rate from the OB star (typically \\sim 10^{49} photon s-1), \\alpha \\sim 3\\times10^{-13} cm3 s-1 is the recombination coefficient, and n\\sim 10 cm-3 is the number density.\n\nWe know r_S. Solve this equation instead for N^*, writing a function that returns the value of\\left(\\frac{N^*}{10^{49}}\\right)\n\nHaving done so, you now have a function that given a radius and assumptions about particle density and recombination coefficient returns the “number” of OB stars driving the HII region! (Technically, we have an answer that is units of the typical OB star’s photon flux, so the actual number of stars could be lower if each is more massive and brighter and vice versa --- but this gives both the actual driving flux and an approximate order-of-magnitude estimate for the number of stars.\n\nPlay with your function a bit, putting in values from 10 pc to 500 pc for the size, and see how the ionizing flux changes!\n\nExercise 3.7: Putting it all together\n\nThroughout the course of this lab, you have written several shorter (and longer) functions. For our implot function, it is hopefully clear why having that function around is handy --- to set everything we included every time we wanted to quickly view some fits file or local array would be onerous; this function now makes it very easy to get a useful result in a simple one line call, with plenty of room to specify options if we desire.\n\nOn the other hand, something we covered in lecture was that functions are most useful for reusable bits of code. Thus far, though, we only measured one HII region. In theory, all of the computations we did along the way could have been done directly in our script or notebook and it would not have been that disorganized of a file.\n\nLet’s now demonstrate why writing functions was useful, even for the small steps.\n\nUsing the original image, pick four more HII regions in the image of M33, and determine their physical sizes and number of OB stars.\n\nTasked with this, hopefully you will be able to re-use your defined functions to make locating and measuring the size of each much easier! Create section headings in your solution with each one. While the solution won’t be fully automatic, since we still have some by-eye assesment happening, the final code block for doing this whole measurement will only be a few lines long, calling our pre-made functions. As we move further into the semester, we will learn how to automate, e.g., finding the locations of features of interest and measuring the size of those features.","type":"content","url":"/assignment-functions#part-ii-the-size-of-hii-regions","position":7},{"hierarchy":{"lvl1":"Astro-RPS Week 6 Lab: Practice with Notebook, Pandas, and Plotting!"},"type":"lvl1","url":"/week6-lab","position":0},{"hierarchy":{"lvl1":"Astro-RPS Week 6 Lab: Practice with Notebook, Pandas, and Plotting!"},"content":"This week’s lab will focus on using the skills you have learned about pandas and matplotlib to do some real scientific data analysis. For today, please write all your code in a Jupyter Notebook!\n\nExercise 1: Plotting a Hertzsprung-Russell Diagram of the Globular Cluster M92 using Data from the Gaia Mission\n\nThe Gaia satellite has collected stellar positions, motions, and brightnesses for nearly two billion stars in the Milky Way. The file “GaiaM92.csv” contains example data from Gaia specifically for the globular star cluster Messier 92 (M92). To investigate the data, take the following steps:\n\nLoad the .csv file into a dataframe called m92_data. Each row in this datafile is an individual star.\n\nPlot a histogram of the column “phot_g_mean_mag”. This is the column that contains the brightnesses of stars.  What do you notice about the distribution?\n\nNow, make a scatterplot with the column “bp_rp” (a proxy for color) on the x-axis and “phot_g_mean_mag” (a proxy for luminosity) on the y-axis. Is the distribution in this plane uniform, or do you see patterns/sequences.\n\nClean up the scatterplot from part 3: first, invert the y-axis so smaller numbers are at the top of the plot, and limit the x range to -0.5 to 2.  Then, change the marker size and color to be small, black points. Lastly, label both axes something physically meaningful (not just the column names)\n\nCompare your diagram to the one shown at this link: \n\nCluster HR Diagram. Can you observe the same features in your plot?\n\nBonus Extension to Exercise 1: The Distance to the Cluster M92\n\nThe horizontal branch of the HR diagram (see Q5 of Exercise 1) is comprised of stars at roughly the same luminosity regardless of temperature. Since we have a sense of the instrinsic (absolute) luminosity of these stars, we can compared that to their observed luminosity to get a sense of their distance. For a globular cluster like M92, we can then average over the distance to these special stars to get a distance to the cluster. In this exercise, we’ll do exactly that!\n\nFirst, isolate the horizontal branch by filtering based on the phot_g_mean_mag column and the bp_rp column. In practice, you need four selections total which select for stars in this feature (e.g, mag > 15 and mag < 16 and similar for bp_rp). I recommend you impose phot_g_mean_mag < 15.5 as one of them to get the best possible results.\n\nThe “absolute” G-band luminosity of stars on the horizontal branch is G = 0.3. Create a new column called “DistanceModulus” which is phot_g_mean_mag minus this number.\n\nThe distance modulus (unitless) is related to the distance (in kiloparsecs) via the formula\\rm distance \\ (kpc) = \\frac{1}{1000}\\left(10^{((DistanceModulus/5) + 1)}\\right)\n\nCreate a column in your dataframe for the distance in kiloparsecs using this formula, and call that column Distance_kpc\n\nCreate a column Distance_lightyears which is just Distance_kpc multiplied by 3262.\n\nLastly, Print the average and standard deviation of your Distance_lightyears column.  What distance is the cluster? If you assume the mean value and the standard deviation as the error, does your value match that shown on the Wikipedia page for M92?\n\nExercise 2: Filtering with Proper Motion Information to Identify a Hidden Dwarf Galaxy in Gaia Data\n\nNow, we will turn to the file \"ReticulumII.csv’, which contains a catalog of stars observed by Gaia in a small region around an “ultra-faint” dwarf galaxy orbiting the Milky Way named Reticulum II. This galaxy is drowned out by foreground stars from the Milky Way disk, which we can cleverly remove using the information from Gaia.\n\nThe .csv file given has a noticeable change that you will need to account for when loading it. Visually inspect the file to figure out what this change is, and then load the file in with pandas using the appropriate arguments needed to handle the changed format.\n\nMake a plot of the “dec” column (y-axis) vs. the “ra” column (x-axis); also, fix the figure size to be square of dimensions 5 x 5 inches. RA (short for Right Ascension) and Dec (short for Declination) are what we call celestial coordinates, and they specify the position of a star, galaxy, or other astronomical object on the sky.\n\nRemove some Milky Way foreground stars by a cut with on parallax: specifically, the new dataframe should contain only the rows with parallax < 0.75. Parallaxes are related to distances via distance (in pc) = 1/parallax, and so removing stars with large parallax with leave us with a sample of only the more distant stars. Store the output in a new dataframe called filtered_stars.\n\nNow, make a plot of the same size but now using the “pmra” column (x-axis) vs the “pmdec” column. Here, the “pm” stands for Proper Motion, which is the apparent change in an astronomical object’s celestial coordinate position due to its motion in the tangential direction (i.e., not along the line of sight, but instead on the plane of the sky).\n\nIn your plot from (4), see whether you can identify a clump of stars with similar proper motions in both the x and y directions. (hint: look near (0,0), and feel free to change the axes limits!). Then, come up with a rectangular selection based on the pmra/pmdec columns that could be used to select for rows consistent with this signal (e.g.. pmra > -5).\n\nFilter your parallax-filtered dataframe from (3), which was called filtered_stars,  using the cuts you defined in (5). You can store the output in a dataframe with the same name, filtered_stars.\n\nNow, plot the same plot from (3) except now using the filtered_stars dataframe. Do you see the dwarf galaxy now?","type":"content","url":"/week6-lab","position":1},{"hierarchy":{"lvl1":"Astro-RPS Week 7 Lab:  Exploring the Diversity of Known Exoplanets"},"type":"lvl1","url":"/rps-week7-exoplanets","position":0},{"hierarchy":{"lvl1":"Astro-RPS Week 7 Lab:  Exploring the Diversity of Known Exoplanets"},"content":"A classic figure often seen in exoplanet research is the mass-separation plot for known exoplanets color-coded according to their detection method. One version of this figure is shown here:\n\nThe x-axis of this figure shows the mass of the planet on a log scale, typically measured in Jupiter masses (where 1 Jupiter mass equals approximately 1.898 × 10^27 kg). The y-axis, also on a log scale, represents the planet-star separation distance, often expressed in astronomical units (AU), with 1 AU equivalent to the average distance between the Earth and the Sun (approximately 149.6 million kilometers). Each data point plotted signifies an individual exoplanet, and the color coding of the data points corresponds to the method employed for exoplanet detection.\n\nHere are a few brief descriptions of how the four listed detection methods work:\n\nTransit Method: In this technique, exoplanets are detected by observing the periodic dimming of a star’s light as a planet passes in front of it (transits) from our line of sight. By measuring the decrease in brightness during transit events, astronomers can infer the presence and characteristics of orbiting planets.\n\nRadial Velocity Method: This method detects exoplanets by measuring the small periodic shifts in the star’s radial velocity caused by the gravitational pull of an orbiting planet. As the planet orbits the star, it causes the star to wobble slightly, which can be detected through Doppler spectroscopy.\n\nMicrolensing: Exoplanets can be detected through gravitational microlensing, where the gravitational field of a foreground star bends and magnifies the light of a background star as well as any orbiting planets. The presence of an exoplanet around the foreground star can be inferred from the temporary increase in brightness observed during the microlensing event.\n\nTransit Timing Variations (TTV): TTV detects exoplanets by measuring the variations in the timing of transit events caused by gravitational interactions between multiple planets within a system. These deviations from the expected transit times provide information about the masses and orbits of the interacting planets.\n\nIn addition to these four, there are a number of other methods of detecting planets (such as direct imaging)!\n\nThis figure illustrates how different detection methods have been more/less successful in finding certain types of exoplanets, revealing biases or limitations in the different detection techniques.\n\nExercise 1: Recreating the Classic Mass-Distance Plot\n\nDownload the full catalog of known exoplanet properties from the NASA Exoplanet Archive. Navigate to the Data Page of \n\nhttps://​exoplanetarchive​.ipac​.caltech​.edu/ , then to the “Confirmed Planetary Systems” link. Hit Download Table --> download as csv.\n\nWithin a Jupyter notebook, load the table you just downloaded into a Pandas dataframe.\n\nUsing the “np.unique” function in numpy applied to your dataframe, figure out all the possible exoplanet discovery methods report in this table (note: as mentioned above the four methods shown in the provided figure are not the only possible methods)!\n\nTry to recreate the figure shown above using the same units, axis scaling (logarithmic scale), and labels/legend! To do this, filter your pandas dataframe by each discovery method and use different calls to plt.scatter() to plot them in stylistically distinct ways.\n\nExercise 2: Recreating Another Classic Plot: Period-Radius Diagram\n\nUsing the same full exoplanet dataframe you downloaded and opened for exercise 1, trying plotting the exoplanet period-radius diagram. This is another classic exoplanet figure! The x-axis typically represents the logarithm of the orbital period of exoplanets, measured in days. The y-axis represents the logarithm of the radius of exoplanets, usually measured in terms of Earth radii.","type":"content","url":"/rps-week7-exoplanets","position":1},{"hierarchy":{"lvl1":"Fitting Models to Data: Bootstrapping"},"type":"lvl1","url":"/bootstrapping-lab","position":0},{"hierarchy":{"lvl1":"Fitting Models to Data: Bootstrapping"},"content":"","type":"content","url":"/bootstrapping-lab","position":1},{"hierarchy":{"lvl1":"Fitting Models to Data: Bootstrapping","lvl2":"The M-sigma Relation"},"type":"lvl2","url":"/bootstrapping-lab#the-m-sigma-relation","position":2},{"hierarchy":{"lvl1":"Fitting Models to Data: Bootstrapping","lvl2":"The M-sigma Relation"},"content":"Last time, we fit a line to the M-sigma relation which related the central black hole mass to velocity dispersion of a galaxy. Today, we will try to use bootstrapping to get an estimate of the uncertainty on our fitted parameters.\n\nFirst, here is the code we need from last time showing how we can fit a line to this dataset:\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('m-sigma.txt')\ndf.head()\n\nlog_BH = np.log10(df.M_bh)\nBH_err = df.M_bh_err # note: we have already converted the errors to logspace for you! \n\nfig, ax = plt.subplots(figsize=(7,7))\nax.errorbar(df.sigma, log_BH, yerr=BH_err, xerr=df.sigma_err, fmt='None', color='gray')\nax.plot(df.sigma, log_BH, 's', color='blue', ms=12, alpha=0.5, mec='k')\nax.set_xlabel('Velocity Dispersion [km/s]', fontsize=16)\nax.tick_params(which='both', top=True, right=True, direction='in', length=6)\nax.set_ylabel(r'log M$_{\\rm BH}$ [$M_{\\odot}$]', fontsize=16);\n\nLast time, we showed you how you could use np.polyfit to fit a line. The code we used to do this looked like:# Fit a straight line (polynomial of degree 1) to the data\ncoefficients = np.polyfit(x, y, deg=1)\n\n# For a first order polynomial, there are two coefficients\n# Extract the slope (m) and intercept (b) from the coefficients\nslope, intercept = coefficients \n\n# Generate points along the fitted line for plotting\nx_fit = np.linspace(min(x), max(x), 100)\ny_fit = slope * x_fit + intercept\n\nWe can do this more efficiently using the np.polyval function to generate y_fit without needing to write out the equation y = mx + b.\n\ncoefficients = np.polyfit(df.sigma,log_BH,deg=1,w=1/BH_err)\nx_fit = np.linspace(50,400,100)\ny_fit = np.polyval(coefficients, x_fit)\n\nfig, ax = plt.subplots(figsize=(7,7))\nax.errorbar(df.sigma, log_BH, yerr=BH_err, xerr=df.sigma_err, fmt='None', color='gray')\nax.plot(df.sigma, log_BH, 's', color='blue', ms=12, alpha=0.5, mec='k')\nax.plot(x_fit, y_fit, 'k', lw=3)\nax.set_xlabel('Velocity Dispersion [km/s]', fontsize=16)\nax.tick_params(which='both', top=True, right=True, direction='in', length=6)\nax.set_ylabel(r'log M$_{\\rm BH}$ [$M_{\\odot}$]', fontsize=16);\n\n","type":"content","url":"/bootstrapping-lab#the-m-sigma-relation","position":3},{"hierarchy":{"lvl1":"Fitting Models to Data: Bootstrapping","lvl3":"Fitting x(y)","lvl2":"The M-sigma Relation"},"type":"lvl3","url":"/bootstrapping-lab#fitting-x-y","position":4},{"hierarchy":{"lvl1":"Fitting Models to Data: Bootstrapping","lvl3":"Fitting x(y)","lvl2":"The M-sigma Relation"},"content":"We also discussed how linear least squares is only accounting for the uncertainties in the independent variable (here our y-axis). But both quantities being plotted had major uncertainties, so we asked you to fit x(y) as well, using the errors on x instead of y. The solution to that attempt is below.\n\ncoeff2 = np.polyfit(log_BH,df.sigma,deg=1,w=1/df.sigma_err)\nin_masses = np.linspace(-1.5,2,100)\nout_velocities = np.polyval(coeff2,in_masses)\n\nfig, ax = plt.subplots(figsize=(7,7))\nax.errorbar(df.sigma, log_BH, yerr=BH_err, xerr=df.sigma_err, fmt='None', color='gray')\nax.plot(df.sigma, log_BH, 's', color='blue', ms=12, alpha=0.5, mec='k')\nax.plot(x_fit, y_fit, 'k', lw=3, label='fit y(x)')\nax.plot(out_velocities, in_masses, 'r', lw=3, label='fit x(y)')\nax.set_xlabel('Velocity Dispersion [km/s]', fontsize=16)\nax.tick_params(which='both', top=True, right=True, direction='in', length=6)\nax.legend()\nax.set_ylabel(r'log M$_{\\rm BH}$ [$M_{\\odot}$]', fontsize=16);\n\n","type":"content","url":"/bootstrapping-lab#fitting-x-y","position":5},{"hierarchy":{"lvl1":"Fitting Models to Data: Bootstrapping","lvl2":"Bootstrap Resampling"},"type":"lvl2","url":"/bootstrapping-lab#bootstrap-resampling","position":6},{"hierarchy":{"lvl1":"Fitting Models to Data: Bootstrapping","lvl2":"Bootstrap Resampling"},"content":"Bootstrapping is a resampling technique used in statistics to estimate the sampling distribution of a statistic by repeatedly sampling with replacement from the observed data. It is particularly useful when the underlying population distribution is unknown or difficult to model.\n\nSample Creation: Bootstrapping starts with the creation of multiple bootstrap samples by randomly selecting observations from the original dataset with replacement. This means that each observation in the original dataset has the same chance of being selected for each bootstrap sample, and some observations may be selected multiple times while others may not be selected at all.\n\nStatistical Estimation: After creating the bootstrap samples, the statistic of interest (e.g., mean, median, standard deviation, regression coefficient) is calculated for each bootstrap sample. This results in a distribution of the statistic across the bootstrap samples, known as the bootstrap distribution. In our case, this would be fitting our line to the data and seeing how much the paramters (slope and intercept) change for each fit. Now, we have some way of expressing uncertainty in our fitted parameters!\n\nThe goal for today is to use bootstrapping to estimate the uncertainty on our fit for the M-sigma relation!\n\n\n\nExercise 1: Bootstrap Resampling for our Linear Fit to the M-sigma Relation\n\nUsing your code from Monday, start by loading the data and fitting a linear model.\n\nPerform Bootstrap Resampling: To do this, you will re-fit the data many times after creating subsamples of\nrandomly drawn datasets (with replacement) from our actual data. In general, you can choose the number of bootstrap samples to generate based on computational resources and desired precision. For this case, you can start by generating ~500 bootstrap samples. For each bootstrap iteration:\n\nGenerate a bootstrap sample from the observed data by randomly sampling with replacement N points from the data where N is the length of the data. Remember: you need to sample x, y, and yerr in some way that preserves the correct ordering (aka you can’t take the black hole mass of one galaxy and the diserpersion of another galaxy!). There is a numpy function that can do this for you, so your first task is to search for this function!\n\nHint\n\nIf you can’t find it, the function you should use for this step is np.random.choice. Look at the documentation to figure out how to implement it.\n\nFor each bootstrap sample, fit a linear model to the resampled data using the same procedure as before (first order polynomial with np.polyfit).\n\nAppend the coefficients (slope and intercept) of the linear fit for each bootstrap sample to a container of your choice (probably a list or array).\n\nVisualize Results: You should generate some plots to assess our bootstrapping results.\n\nFirst, add all 500 lines from your 500 bootstrap fits to your original M-sigma plot. Note: use a low alpha for your plots so the lines are semi-transparent!\n\nPlot histograms or density plots of the distributions of slopes and intercepts obtained from the bootstrap resampling. Additionally, overlay the slope and intercept derived from the original linear fit on the same plot for comparison.\n\nEvaluate and Interpret: Examine the distribution of slopes and intercepts across the bootstrap samples to assess their variability and uncertainty. How well-constrained is our fit to the M-sigma relation on the basis of this data?","type":"content","url":"/bootstrapping-lab#bootstrap-resampling","position":7},{"hierarchy":{"lvl1":"Moving beyond polynomials: Fitting arbitrary functions"},"type":"lvl1","url":"/gaussian-lab","position":0},{"hierarchy":{"lvl1":"Moving beyond polynomials: Fitting arbitrary functions"},"content":"In some cases, the relationship between variables in our data may not be well described by a simple polynomial function. When this happens, we need to use more flexible methods that allow us to fit arbitrary functions to our data. One such method is the curve_fit function from the SciPy library, which enables us to fit user-defined functions to our data using non-linear least squares optimization.","type":"content","url":"/gaussian-lab","position":1},{"hierarchy":{"lvl1":"Moving beyond polynomials: Fitting arbitrary functions","lvl2":"Using curve_fit in SciPy:"},"type":"lvl2","url":"/gaussian-lab#using-curve-fit-in-scipy","position":2},{"hierarchy":{"lvl1":"Moving beyond polynomials: Fitting arbitrary functions","lvl2":"Using curve_fit in SciPy:"},"content":"The curve_fit function in SciPy is a powerful tool for fitting arbitrary functions to data using non-linear least squares optimization. It takes as input a user-defined model function, along with the observed data and optional initial parameter estimates, and returns the optimal parameter values that minimize the sum of squared residuals between the model predictions and the observed data.","type":"content","url":"/gaussian-lab#using-curve-fit-in-scipy","position":3},{"hierarchy":{"lvl1":"Moving beyond polynomials: Fitting arbitrary functions","lvl3":"Example: Fitting a Line to the M-sigma Relation using curve_fit","lvl2":"Using curve_fit in SciPy:"},"type":"lvl3","url":"/gaussian-lab#example-fitting-a-line-to-the-m-sigma-relation-using-curve-fit","position":4},{"hierarchy":{"lvl1":"Moving beyond polynomials: Fitting arbitrary functions","lvl3":"Example: Fitting a Line to the M-sigma Relation using curve_fit","lvl2":"Using curve_fit in SciPy:"},"content":"\n\n# First, copy our code from last time to read in the m-sigma data and fit a line with polyfit\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('m-sigma.txt')\nlog_BH = np.log10(df.M_bh)\nBH_err = df.M_bh_err\n\ncoefficients = np.polyfit(df.sigma,log_BH,deg=1,w=1/BH_err)\nx_fit = np.linspace(50,400,100)\ny_fit = np.polyval(coefficients, x_fit)\n\nfrom scipy.optimize import  curve_fit\n\n# Define a linear model function (y = mx + b)\ndef linear_model(x, m, b):\n    return m * x + b\n\n# Perform curve fitting to estimate parameters (slope and intercept)\npopt, pcov = curve_fit(linear_model, df.sigma, log_BH)\n\n# Extract estimated parameters\nslope, intercept = popt\n\nWe usually call the outputs of curve_fit popt and pcov. These represent:\n\npopt: This variable holds the best estimates of the parameters (e.g., slope and intercept) for the fitted model. It’s what we use to get the actual values of the parameters we’re interested in. The ordering of popt matches the ordering of the paramters in our linear_model user defined function after the first arguement (which is the data x).\n\npcov: This variable represents the covariance matrix, which tells us about the uncertainty or correlation between the estimated parameters. It helps us understand how reliable our parameter estimates are. Specifically, it provides information about how much the estimated parameters vary together. If two parameters are highly correlated, changes in one may influence the estimate of the other. For now, we can ignore this.\n\nfig, ax = plt.subplots(figsize=(7,7))\nax.errorbar(df.sigma, log_BH, yerr=BH_err, xerr=df.sigma_err, fmt='None', color='gray')\nax.plot(df.sigma, log_BH, 's', color='blue', ms=12, alpha=0.5, mec='k')\n\nax.plot(x_fit, y_fit, 'k', lw=3, label = 'Polyfit Line')\nax.plot(df.sigma, linear_model(df.sigma, slope, intercept), color='red', label='Curve Fit Line')\n\nax.set_xlabel('Velocity Dispersion [km/s]', fontsize=16)\nax.tick_params(which='both', top=True, right=True, direction='in', length=6)\nax.set_ylabel(r'log M$_{\\rm BH}$ [$M_{\\odot}$]', fontsize=16)\nax.legend();\n\nNote: these fits may be slightly different because we are not incorporating errors in the fit using curve_fit.\n\n","type":"content","url":"/gaussian-lab#example-fitting-a-line-to-the-m-sigma-relation-using-curve-fit","position":5},{"hierarchy":{"lvl1":"Moving beyond polynomials: Fitting arbitrary functions","lvl2":"A Common Use-Case: Gaussian Fitting"},"type":"lvl2","url":"/gaussian-lab#a-common-use-case-gaussian-fitting","position":6},{"hierarchy":{"lvl1":"Moving beyond polynomials: Fitting arbitrary functions","lvl2":"A Common Use-Case: Gaussian Fitting"},"content":"Gaussian fitting, also known as Gaussian curve fitting or Gaussian distribution fitting, is a statistical method used to model data that follows a Gaussian (normal) distribution. A Gaussian distribution is characterized by its bell-shaped curve, which is symmetrical around the mean and describes the probability distribution of a continuous random variable. Gaussian fitting involves estimating the parameters of a Gaussian function, such as the mean, standard deviation, and amplitude, that best describe the observed data.\n\nGaussian fitting is important in many aspects of astronomy, as we expect many distributions to be well-described by Gaussians. A\nGaussian can be expressed as:f(x) = A \\cdot e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\n\nMean (μ): The center or average value of the Gaussian distribution.\n\nStandard Deviation (σ): The measure of the spread or dispersion of the Gaussian distribution.\n\nAmplitude (A): The peak height or maximum value of the Gaussian curve.\n\nExercise 1: Fitting a Gaussian to Synthetic Data\n\nUsing the curve_fit function, fit a Gaussian function to the noisy data provided below and estimate the parameters that best describe the underlying Gaussian distribution.\n\nCopy the starter code below: Begin by copying the starter code to generate synthetic data representing noisy measurements of a Gaussian distribution. The data consists of input values (x) and corresponding noisy observations (y_noise).\n\nDefine the Gaussian Model Function: Define a Gaussian model function representing the mathematical form of a Gaussian distribution. The Gaussian function should take input variables (e.g., x) and parameters (e.g., mean, standard deviation, amplitude) as arguments and return the predicted values of the Gaussian distribution.\n\nPerform Curve Fitting: Use the curve_fit function from the SciPy library to fit the Gaussian model function to the noisy data. Provide the input data (x) and noisy observations (y_noise) as input arguments to curve_fit. Optionally, you can provide initial estimates for the parameters to aid the fitting process. Look at the curve_fit documentation to see how to do this!\n\nVisualize the Fitted Gaussian: Plot the noisy data along with the fitted Gaussian distribution to visualize how well the Gaussian model fits the observed data.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\n\n# Generate synthetic data following a Gaussian distribution\nx = np.linspace(-5, 5, 100)\ny_true = np.exp(-0.5 * (x ** 2)) / np.sqrt(2 * np.pi)  # True Gaussian distribution\n\n# Add noise to the data to simulate experimental measurements\nnp.random.seed(0)\ny_noise = y_true + np.random.normal(loc=0, scale=0.1, size=len(x))\n\nfig, ax = plt.subplots(figsize=(7,7))\nax.scatter(x, y_noise, color='blue', label='Noisy Data')\nax.plot(x, y_true, linestyle='--', color='green', label='True Gaussian Distribution')\nax.set_xlabel('x', fontsize=14)\nax.set_ylabel('y', fontsize=14)\nax.tick_params(which='both', top=True, right=True, direction='in', length=6)\nax.legend();\n\nExercise 2: Fitting a Gaussian to a Real Galaxy Spectrum!\n\nOn slack, we will send a data file with a galaxy spectrum that has the columns wave, flux, and ivar. These stand for the wavelength array (which you would plot on the x-axis), the flux or intensity of emission at every given wavelength (which you would plot on the y-axis), and the inverse variance for each flux measurement.\n\nLoad in this data, and slice the arrays to select for the H-alpha emission line (this is the largest emission line in this spectrum). Then, using your Gaussian fitting code to fit a Gaussian to the H-alpha line and report the line center and line width.","type":"content","url":"/gaussian-lab#a-common-use-case-gaussian-fitting","position":7},{"hierarchy":{"lvl1":"Course Topics by Week"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Course Topics by Week"},"content":"\nThis workshop series will focus on an introduction to the Python programming language in the context of physics and astrophysics applications. All research carried in these scientific fields requires the use of extensive programming, making it a bedrock skill of any scientist. In this seminar, we will start from square one, covering how to install and navigate the programming ecosystem such as the terminal/shell, before moving into how to create scientific programs in python to carry out calculations one might use in a research project. This workshop series is primarily intended for students with little to no exposure to coding or astronomy research. After taking this series, students should be prepared to tackle programming-based courses (e.g., ASTR 255/330) as well as feel comfortable applying to summer research positions.\n\nThis series meets twice a week in the afternoon (M/W 5-6). Monday sessions will have (interactive) lectures in which a new programming concept is introduced. Wednesday is a “lab” in which students will work on a weekly assignment targeting those concepts. We expect most students to finish the weekly assignment during the Wednesday session, but they are due the following Tuesday, so time can be taken outside of the seminar if needed.\n\nIf you are interested in participating in the workshop series, please fill out \n\nTHIS INTEREST FORM!","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Course Topics by Week"},"type":"lvl1","url":"/#course-topics-by-week","position":2},{"hierarchy":{"lvl1":"Course Topics by Week"},"content":"Week 1 (Jan 29):\n\nUNIX, filesystems, environments and the Python ecosystem\n\nWeek 2 (Feb 5):\n\nPure Python programming, calculations, variables, datatypes and scripts\n\nIntroduction to numpy\n\nWeek 3 (Feb 12):\n\nControl flow, loops, program logic, and an introduction to libraries\n\nWeek 4 (Feb 19):\n\nFunctions and functional programming\n\nIntroduction to ipython notebooks (jupyter)\n\nWeek 5 (Feb 26):\n\nVectorization and program efficiency\n\nFinal project introductions\n\nWeek 6 (March 4):\n\nWorking with astrophysical datasets (loading, analyzing, fitting, visualizing)\n\nSpring Break\n\nWeek 7 (March 25):\n\nIntroduction to Object Oriented Programming\n\nWeek 8 (April 1):\n\nIntroduction to github and version control + Bonus Content\n\nWeek 9 (April 8):\n\nFinal presentations\n\nFor a more detailed topic list, \n\nclick here","type":"content","url":"/#course-topics-by-week","position":3},{"hierarchy":{"lvl1":"Course Topics"},"type":"lvl1","url":"/topiclist","position":0},{"hierarchy":{"lvl1":"Course Topics"},"content":"UNIX, Filesystems, Environments and the Python Ecosystem\n\nIn this module we will familiarize students with the command line interface of computer operating systems, teach common unix commands, and discuss the installation of environments with Python, and where that is situated in the broader coding ecosystem.\n\nDiscussion of the differences between CS and DS/astronomy analysis\n\nPure Python Programming, Calculations, Variables, Datatypes and Scripts\n\nIn this module, we introduce the basic python syntax, including variable declaration, basic mathematical operations, and the built-in datatypes (+numpy). We will transition from the iPython interpreter to standalone python scripts.3/\n\nControl flow, Loops, Program Logic, and an introduction to Libraries (astropy+matplotlib)\n\nIn this module we will first expand the set of applications by discussing package imports (beyond numpy), including matplotlib and astropy. We will then use relevant examples from these packages to teach program logic and control flow (if/else, try/except) and looping (for/while).\n\nWe will also take time here to discuss the parsing of error messages and how to debug errors in code.\n\nFunctions and Functional Programming, Notebooks\n\nUsing examples from astropy+matplotlib+numpy, we will introduce the creation of user-defined functions in Python, their benefits, and best practices for documentation, including type annotations.\n\nAt this point, we will introduce the concept of jupyter notebooks, how they differ from standard scripts, and common pitfalls. We will provide a framework for development in notebooks by which functions are created and tested and then moved to a python module for import and use.\n\nVectorization, Program Efficiency, and Final Project Introductions\n\nIn this module we will discuss common programming pitfalls that lead to inefficient (slow) code, and we will formally introduce several methods to write code that will run as quickly as possible.\n\nWe will also introduce the final projects and get students thinking about ideas.\n\nWorking with Astrophysical Datasets (Loading, Analyzing, Fitting, Visualizing)\n\nIn this module, we will discuss several different libraries (including pandas) in the context of loading and working with more complex astronomical data (beyond individual fits images or simple two column tables) and different file types (csv, fits, hdf5, json). Additionally, retrieving data from online servers and catalogs (e.g., astroquery and sql).\n\nWe will discuss real statistical analyses one would apply to these data, and demonstrate several ways of carrying out model fits (e.g., with polyfit, spline fits, chi^2 grid searches, or mcmc).\n\nFinally, we will touch on more advanced plotting techniques for “publication” plots and figures which capture rich datasets.\n\nSpring Break (end of regular seminar content/assignments)\n\nIntroduction to Object Oriented Programming\n\nWe return to introductory discussions of objects in python and the OOP paradigm of creating objects with methods and attributes. We will show how to create simple classes that may be useful to students.\nNote there is no explicit lab for this; students are working on their final projects in class.\n\nIntroduction to Github and Version Control + Bonus Content\n\nWe will introduce the students to the basic use of github for version control. This will in turn prepare them to upload their final projects to github.\n\nWe have several “Bonus Content” Topics that we will allow the students to choose from during these last few weeks while the focus is on their final projects. There are no “regular” assignments for these weeks. Topics include:\n\nHTML/CSS and building a personal website\n\nLaTeX typesettings (for papers or homework)\n\nMore OOP discussion\n\nFinal Project Presentations\n\nFinally, we invite the students to present their final project demonstrations to the class. These projects represent several weeks of coding effort. Students are encouraged to choose any topic that interests them; we have had projects spanning the range from implementing a game like chess or battleship, to astronomy themed projects such as writing a simple integrator or simulating galaxy collisions. We will (potentially) be inviting the department at large to attend these presentations.","type":"content","url":"/topiclist","position":1}]}