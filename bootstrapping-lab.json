{"kind":"Notebook","sha256":"2ff4c7f73a0a48c4996989d8cc5a5fc66b256810195925852c9a2336bb2ec66d","slug":"bootstrapping-lab","location":"/02_Labs/Week 8/bootstrapping_lab.ipynb","dependencies":[],"frontmatter":{"title":"Fitting Models to Data: Bootstrapping","github":"https://astro-rps.github.io/","keywords":[],"thumbnail":"/build/bootstrap_resampling-7ec0da12281d7c1bce988260308d21fe.png","exports":[{"format":"ipynb","filename":"bootstrapping_lab.ipynb","url":"/build/bootstrapping_lab-1260298c00701a91a712b77acf647aee.ipynb"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The M-sigma Relation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wihB9H7WcO"}],"identifier":"the-m-sigma-relation","label":"The M-sigma Relation","html_id":"the-m-sigma-relation","implicit":true,"key":"hxmkT8s9js"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Last time, we fit a line to the M-sigma relation which related the central black hole mass to velocity dispersion of a galaxy. Today, we will try to use bootstrapping to get an estimate of the uncertainty on our fitted parameters.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"eYzAdnHLde"}],"key":"opmq4rp57z"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"First, here is the code we need from last time showing how we can fit a line to this dataset:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"P3KEVnlCsn"}],"key":"IufAy2hTZM"}],"data":{"type":"notebook-content"},"key":"svmuDlnBfE"},{"type":"block","children":[{"type":"code","lang":"python","executable":true,"value":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('m-sigma.txt')\ndf.head()","key":"GubUoFreba"},{"type":"output","id":"tO3Z9JzawUbq6mLtTBNBL","data":[{"output_type":"execute_result","execution_count":1,"metadata":{},"data":{"text/html":{"content":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Galaxy</th>\n      <th>M_bh</th>\n      <th>sigma</th>\n      <th>sigma_err</th>\n      <th>M_bh_err</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MW</td>\n      <td>0.0295</td>\n      <td>100</td>\n      <td>20</td>\n      <td>0.051492</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I1459</td>\n      <td>4.6000</td>\n      <td>312</td>\n      <td>41</td>\n      <td>0.264174</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>N221</td>\n      <td>0.0390</td>\n      <td>76</td>\n      <td>10</td>\n      <td>0.100154</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>N3115</td>\n      <td>9.2000</td>\n      <td>278</td>\n      <td>36</td>\n      <td>0.141522</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>N3379</td>\n      <td>1.3500</td>\n      <td>201</td>\n      <td>26</td>\n      <td>0.234681</td>\n    </tr>\n  </tbody>\n</table>\n</div>","content_type":"text/html"},"text/plain":{"content":"  Galaxy    M_bh  sigma  sigma_err  M_bh_err\n0     MW  0.0295    100         20  0.051492\n1  I1459  4.6000    312         41  0.264174\n2   N221  0.0390     76         10  0.100154\n3  N3115  9.2000    278         36  0.141522\n4  N3379  1.3500    201         26  0.234681","content_type":"text/plain"}}}],"key":"Qr2imBQRUj"}],"data":{"type":"notebook-code"},"key":"Owg5ICaseP"},{"type":"block","children":[{"type":"code","lang":"python","executable":true,"value":"log_BH = np.log10(df.M_bh)\nBH_err = df.M_bh_err # note: we have already converted the errors to logspace for you! ","key":"wczfwcxj3Y"},{"type":"output","id":"txpYLE34maroQ8At-PLJJ","data":[],"key":"knQ6bjEl2K"}],"data":{"type":"notebook-code"},"key":"vezIHy8jh3"},{"type":"block","children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots(figsize=(7,7))\nax.errorbar(df.sigma, log_BH, yerr=BH_err, xerr=df.sigma_err, fmt='None', color='gray')\nax.plot(df.sigma, log_BH, 's', color='blue', ms=12, alpha=0.5, mec='k')\nax.set_xlabel('Velocity Dispersion [km/s]', fontsize=16)\nax.tick_params(which='both', top=True, right=True, direction='in', length=6)\nax.set_ylabel(r'log M$_{\\rm BH}$ [$M_{\\odot}$]', fontsize=16);","key":"PnWmuTR9Ux"},{"type":"output","id":"V2WdJ3u2FB7eGI2O84H5D","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"84b76455d4bb4e0326faa47db081a93e","path":"/build/84b76455d4bb4e0326faa47db081a93e.png"},"text/plain":{"content":"<Figure size 700x700 with 1 Axes>","content_type":"text/plain"}}}],"key":"lpDEw9doL1"}],"data":{"type":"notebook-code"},"key":"XVdLpTcLaA"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Last time, we showed you how you could use ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OjpItRVKlN"},{"type":"inlineCode","value":"np.polyfit","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DY05nEIpfU"},{"type":"text","value":" to fit a line. The code we used to do this looked like:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sk42YGboQC"}],"key":"jQFKEpml6G"},{"type":"code","lang":"","value":"# Fit a straight line (polynomial of degree 1) to the data\ncoefficients = np.polyfit(x, y, deg=1)\n\n# For a first order polynomial, there are two coefficients\n# Extract the slope (m) and intercept (b) from the coefficients\nslope, intercept = coefficients \n\n# Generate points along the fitted line for plotting\nx_fit = np.linspace(min(x), max(x), 100)\ny_fit = slope * x_fit + intercept","position":{"start":{"line":2,"column":1},"end":{"line":13,"column":1}},"key":"BymVeC05JO"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"We can do this more efficiently using the ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"jDw3ACfqQr"},{"type":"inlineCode","value":"np.polyval","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"FVO2EDllAS"},{"type":"text","value":" function to generate ","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"PwKpjebDE8"},{"type":"inlineCode","value":"y_fit","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"lQq9beLP5k"},{"type":"text","value":" without needing to write out the equation y = mx + b.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"TPy4dxOknE"}],"key":"PbV8aRP2TM"}],"data":{"type":"notebook-content"},"key":"pp0pNnrW9i"},{"type":"block","children":[{"type":"code","lang":"python","executable":true,"value":"coefficients = np.polyfit(df.sigma,log_BH,deg=1,w=1/BH_err)\nx_fit = np.linspace(50,400,100)\ny_fit = np.polyval(coefficients, x_fit)","key":"EihGI0kS4s"},{"type":"output","id":"rdKhUzPXgQ_OxJo-vi4FP","data":[],"key":"JugnQWwZ86"}],"data":{"type":"notebook-code"},"key":"OBj5Ejm2IY"},{"type":"block","children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots(figsize=(7,7))\nax.errorbar(df.sigma, log_BH, yerr=BH_err, xerr=df.sigma_err, fmt='None', color='gray')\nax.plot(df.sigma, log_BH, 's', color='blue', ms=12, alpha=0.5, mec='k')\nax.plot(x_fit, y_fit, 'k', lw=3)\nax.set_xlabel('Velocity Dispersion [km/s]', fontsize=16)\nax.tick_params(which='both', top=True, right=True, direction='in', length=6)\nax.set_ylabel(r'log M$_{\\rm BH}$ [$M_{\\odot}$]', fontsize=16);","key":"Ou8yMMZdml"},{"type":"output","id":"oJMFSGS7vkWd8PBLcmbyQ","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"246c5382011286c6f5c80491b3d77e22","path":"/build/246c5382011286c6f5c80491b3d77e22.png"},"text/plain":{"content":"<Figure size 700x700 with 1 Axes>","content_type":"text/plain"}}}],"key":"wA8IrpnITv"}],"data":{"type":"notebook-code"},"key":"FpKC5DmsWo"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Fitting x(y)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WH81aYeeVW"}],"identifier":"fitting-x-y","label":"Fitting x(y)","html_id":"fitting-x-y","implicit":true,"key":"i7WVbfHR7N"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"We also discussed how linear least squares is only accounting for the uncertainties in the independent variable (here our ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BciYlO07L9"},{"type":"inlineMath","value":"y","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"html":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span></span></span></span>","key":"DhKufUSbzw"},{"type":"text","value":"-axis). But both quantities being plotted had major uncertainties, so we asked you to fit x(y) as well, using the errors on x instead of y. The solution to that attempt is below.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"zVXCyM1Btt"}],"key":"s63R7vwuQP"}],"data":{"type":"notebook-content"},"key":"TgMdjhAnId"},{"type":"block","children":[{"type":"code","lang":"python","executable":true,"value":"coeff2 = np.polyfit(log_BH,df.sigma,deg=1,w=1/df.sigma_err)\nin_masses = np.linspace(-1.5,2,100)\nout_velocities = np.polyval(coeff2,in_masses)","key":"x0DxRulBc3"},{"type":"output","id":"6j_SE2vQvWSLyTbTjqurM","data":[],"key":"ih1gMSOVbD"}],"data":{"type":"notebook-code"},"key":"jmrCIgSw5O"},{"type":"block","children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots(figsize=(7,7))\nax.errorbar(df.sigma, log_BH, yerr=BH_err, xerr=df.sigma_err, fmt='None', color='gray')\nax.plot(df.sigma, log_BH, 's', color='blue', ms=12, alpha=0.5, mec='k')\nax.plot(x_fit, y_fit, 'k', lw=3, label='fit y(x)')\nax.plot(out_velocities, in_masses, 'r', lw=3, label='fit x(y)')\nax.set_xlabel('Velocity Dispersion [km/s]', fontsize=16)\nax.tick_params(which='both', top=True, right=True, direction='in', length=6)\nax.legend()\nax.set_ylabel(r'log M$_{\\rm BH}$ [$M_{\\odot}$]', fontsize=16);","key":"QALjFepnv3"},{"type":"output","id":"ltOSBYv0-gZVY_0OZAQn2","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"83f8852746e5eb039c9fd6fda97d7d7d","path":"/build/83f8852746e5eb039c9fd6fda97d7d7d.png"},"text/plain":{"content":"<Figure size 700x700 with 1 Axes>","content_type":"text/plain"}}}],"key":"M4Eokb4l8D"}],"data":{"type":"notebook-code"},"key":"BYxZpCJUby"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Bootstrap Resampling","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DQOPp0d2hK"}],"identifier":"bootstrap-resampling","label":"Bootstrap Resampling","html_id":"bootstrap-resampling","implicit":true,"key":"iXj3QgO60E"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Bootstrapping is a resampling technique used in statistics to estimate the sampling distribution of a statistic by repeatedly sampling with replacement from the observed data. It is particularly useful when the underlying population distribution is unknown or difficult to model.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gIbnCBaRrs"}],"key":"D5ljGZLmrS"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Sample Creation: Bootstrapping starts with the creation of multiple bootstrap samples by randomly selecting observations from the original dataset with replacement. This means that each observation in the original dataset has the same chance of being selected for each bootstrap sample, and some observations may be selected multiple times while others may not be selected at all.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"EWdp8jkAwN"}],"key":"wZaY5yFp85"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Statistical Estimation: After creating the bootstrap samples, the statistic of interest (e.g., mean, median, standard deviation, regression coefficient) is calculated for each bootstrap sample. This results in a distribution of the statistic across the bootstrap samples, known as the bootstrap distribution. In our case, this would be fitting our line to the data and seeing how much the paramters (slope and intercept) change for each fit. Now, we have some way of expressing uncertainty in our fitted parameters!","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"EXSwVFJyX0"}],"key":"dXHP9iYKhc"}],"key":"JoCBwOPPfw"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"The goal for today is to use bootstrapping to estimate the uncertainty on our fit for the M-sigma relation!","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"uG6Kq7yOKO"}],"key":"WmTtcjE9hZ"}],"data":{"type":"notebook-content"},"key":"MSYWjlcqbG"},{"type":"block","children":[{"type":"image","url":"/build/bootstrap_resampling-7ec0da12281d7c1bce988260308d21fe.png","alt":"bootstrapping_image","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mzNcbq3N1Z","urlSource":"bootstrap_resampling.png"}],"data":{"type":"notebook-content"},"key":"j49jxZOhYs"},{"type":"block","children":[{"type":"admonition","class":"tip","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Exercise 1: Bootstrap Resampling for our Linear Fit to the M-sigma Relation","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yFjETzHuIX"}],"key":"i7YTsXFCtP"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Using your code from Monday, start by loading the data and fitting a linear model.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"R4Xddphzz0"}],"key":"bcXRd5zjpx"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":6,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Perform Bootstrap Resampling:","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"A3sRayIabm"}],"key":"nQxwVzNo26"},{"type":"text","value":" To do this, you will re-fit the data many times after creating subsamples of\nrandomly drawn datasets (","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"lqxH0sEsYG"},{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"with replacement","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"P9MaTh0VgK"}],"key":"Az0BIGCpEy"},{"type":"text","value":") from our actual data. In general, you can choose the number of bootstrap samples to generate based on computational resources and desired precision. For this case, you can start by generating ~500 bootstrap samples. For each bootstrap iteration:","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"NmqVdcxgzl"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Generate a bootstrap sample from the observed data by randomly sampling with replacement N points from the data where N is the length of the data. Remember: you need to sample x, y, and yerr in some way that preserves the correct ordering (aka you can’t take the black hole mass of one galaxy and the diserpersion of another galaxy!). There is a numpy function that can do this for you, so your first task is to search for this function!","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"sR8O1hxew5"}],"key":"Fn2tWrbdNC"}],"key":"eH8txyw2Bp"},{"type":"admonition","kind":"hint","class":"dropdown","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Hint","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"DjPdY98moa"}],"key":"Rw4UtPrnS0"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"If you can’t find it, the function you should use for this step is ","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"iwwwDuXFbK"},{"type":"inlineCode","value":"np.random.choice","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"GIkENDaEnR"},{"type":"text","value":". Look at the documentation to figure out how to implement it.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"B8tI2lscho"}],"key":"lTRKGHA3g6"}],"key":"aXgjpyYzL1"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":13,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"For each bootstrap sample, fit a linear model to the resampled data using the same procedure as before (first order polynomial with ","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"WDGA0iUbsA"},{"type":"inlineCode","value":"np.polyfit","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"fl5EqVWiiF"},{"type":"text","value":").","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"aSduyNJz9e"}],"key":"juhIrygVey"},{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Append the coefficients (slope and intercept) of the linear fit for each bootstrap sample to a container of your choice (probably a list or array).","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"fvrue6W8iN"}],"key":"erjBjKacxQ"}],"key":"I1zBRVHepc"}],"key":"N5naPG3s2x"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"strong","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Visualize Results:","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"k4ybK6lVoA"}],"key":"TEiamLpHxU"},{"type":"text","value":" You should generate some plots to assess our bootstrapping results.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"Pm1WKgF3fI"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":16,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"First, add all 500 lines from your 500 bootstrap fits to your original M-sigma plot. Note: use a low ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"NS4qIo78nB"},{"type":"inlineCode","value":"alpha","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"p4MqRkmEm1"},{"type":"text","value":" for your plots so the lines are semi-transparent!","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"l2oEYd5HJD"}],"key":"PWkoQtPtpN"},{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Plot histograms or density plots of the distributions of slopes and intercepts obtained from the bootstrap resampling. Additionally, overlay the slope and intercept derived from the original linear fit on the same plot for comparison.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"IIhryHJ5jd"}],"key":"OtiW0rnoJj"}],"key":"EN2TyWalMR"}],"key":"PaEyC5rpiM"},{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"strong","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Evaluate and Interpret:","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"f6aoBAihLd"}],"key":"u8pHaQdSPc"},{"type":"text","value":" Examine the distribution of slopes and intercepts across the bootstrap samples to assess their variability and uncertainty. How well-constrained is our fit to the M-sigma relation on the basis of this data?","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"momRc6khPa"}],"key":"BA2AhAcUat"}],"key":"NUVZ17NsJR"}],"key":"txTn6BxUtS"}],"data":{"type":"notebook-content"},"key":"pySEQOa99n"}],"key":"qHtJAgTlsS"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Astro-RPS Week 7 Lab:  Exploring the Diversity of Known Exoplanets","url":"/rps-week7-exoplanets","group":"Week  7"},"next":{"title":"Moving beyond polynomials: Fitting arbitrary functions","url":"/gaussian-lab","group":"Week  8"}}},"domain":"http://localhost:3002"}